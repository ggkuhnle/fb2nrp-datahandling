{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "title-cell",
      "metadata": {},
      "source": [
        "# FB2NEP Workbook 2 – Data Collection and Cleaning\n",
        "\n",
        "Version 0.1.0\n",
        "\n",
        "This workbook introduces:\n",
        "\n",
        "- Data collection pipelines in nutritional epidemiology.\n",
        "- Types of variables (continuous, categorical, ordinal, count) and how we code them.\n",
        "- Identification of implausible or inconsistent values.\n",
        "- Handling missing data (MCAR, MAR, MNAR – overview).\n",
        "- Simple validation and visual checks.\n",
        "- Practical issues such as “prefer not to say”, test questions, and units.\n",
        "\n",
        "Run the first code cell to set up the repository and load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bootstrap-cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# FB2NEP bootstrap cell (works both locally and in Colab)\n",
        "#\n",
        "# What this cell does:\n",
        "# - Ensures that we are inside the fb2nep-epi repository.\n",
        "# - In Colab: clones the repository from GitHub if necessary.\n",
        "# - Loads and runs scripts/bootstrap.py.\n",
        "# - Makes the main dataset available as the variable `df`.\n",
        "#\n",
        "# Important:\n",
        "# - You may see messages printed below (for example from pip\n",
        "#   or from the bootstrap script). This is expected.\n",
        "# - You may also see WARNINGS (often in yellow). In most cases\n",
        "#   these are harmless and can be ignored for this module.\n",
        "# - The main thing to watch for is a red error traceback\n",
        "#   (for example FileNotFoundError, ModuleNotFoundError).\n",
        "#   If that happens, please re-run this cell first. If the\n",
        "#   error persists, ask for help.\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import pathlib\n",
        "import subprocess\n",
        "import importlib.util\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Configuration: repository location and URL\n",
        "# ------------------------------------------------------------\n",
        "# REPO_URL: address of the GitHub repository.\n",
        "# REPO_DIR: folder name that will be created when cloning.\n",
        "REPO_URL = \"https://github.com/ggkuhnle/fb2nep-epi.git\"\n",
        "REPO_DIR = \"fb2nep-epi\"\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1. Ensure we are inside the fb2nep-epi repository\n",
        "# ------------------------------------------------------------\n",
        "# In local Jupyter, you may already be inside the repository,\n",
        "# for example in fb2nep-epi/notebooks.\n",
        "#\n",
        "# In Colab, the default working directory is /content, so\n",
        "# we need to clone the repository into /content/fb2nep-epi\n",
        "# and then change into that folder.\n",
        "cwd = pathlib.Path.cwd()\n",
        "\n",
        "# Case A: we are already in the repository (scripts/bootstrap.py exists here)\n",
        "if (cwd / \"scripts\" / \"bootstrap.py\").is_file():\n",
        "    repo_root = cwd\n",
        "\n",
        "# Case B: we are outside the repository (for example in Colab)\n",
        "else:\n",
        "    repo_root = cwd / REPO_DIR\n",
        "\n",
        "    # Clone the repository if it is not present yet\n",
        "    if not repo_root.is_dir():\n",
        "        print(f\"Cloning repository from {REPO_URL} into {repo_root} ...\")\n",
        "        subprocess.run([\"git\", \"clone\", REPO_URL, str(repo_root)], check=True)\n",
        "    else:\n",
        "        print(f\"Using existing repository at {repo_root}\")\n",
        "\n",
        "    # Change the working directory to the repository root\n",
        "    os.chdir(repo_root)\n",
        "    repo_root = pathlib.Path.cwd()\n",
        "\n",
        "print(f\"Repository root set to: {repo_root}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2. Load scripts/bootstrap.py as a module and call init()\n",
        "# ------------------------------------------------------------\n",
        "# The shared bootstrap script contains all logic to:\n",
        "# - Ensure that required Python packages are installed.\n",
        "# - Ensure that the synthetic dataset exists (and generate it\n",
        "#   if needed).\n",
        "# - Load the dataset into a pandas DataFrame.\n",
        "#\n",
        "# We load the script as a normal Python module (fb2nep_bootstrap)\n",
        "# and then call its init() function.\n",
        "bootstrap_path = repo_root / \"scripts\" / \"bootstrap.py\"\n",
        "\n",
        "if not bootstrap_path.is_file():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Could not find {bootstrap_path}. \"\n",
        "        \"Please check that the fb2nep-epi repository structure is intact.\"\n",
        "    )\n",
        "\n",
        "# Create a module specification from the file\n",
        "spec = importlib.util.spec_from_file_location(\"fb2nep_bootstrap\", bootstrap_path)\n",
        "bootstrap = importlib.util.module_from_spec(spec)\n",
        "sys.modules[\"fb2nep_bootstrap\"] = bootstrap\n",
        "\n",
        "# Execute the bootstrap script in the context of this module\n",
        "spec.loader.exec_module(bootstrap)\n",
        "\n",
        "# The init() function is defined in scripts/bootstrap.py.\n",
        "# It returns:\n",
        "# - df   : the main synthetic cohort as a pandas DataFrame.\n",
        "# - CTX  : a small context object with paths, flags and settings.\n",
        "df, CTX = bootstrap.init()\n",
        "\n",
        "# Optionally expose a few additional useful variables from the\n",
        "# bootstrap module (if they exist). These are not essential for\n",
        "# most analyses, but can be helpful for advanced use.\n",
        "for name in [\"CSV_REL\", \"REPO_NAME\", \"REPO_URL\", \"IN_COLAB\"]:\n",
        "    if hasattr(bootstrap, name):\n",
        "        globals()[name] = getattr(bootstrap, name)\n",
        "\n",
        "print(\"Bootstrap completed successfully.\")\n",
        "print(\"The main dataset is available as the variable `df`.\")\n",
        "print(\"The context object is available as `CTX`.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "var-types-intro",
      "metadata": {},
      "source": [
        "## 1. Variable types and coding\n",
        "\n",
        "Before we think about *where* data come from, we need to understand *what kind of things* we can measure.\n",
        "\n",
        "In this workbook we will repeatedly use three broad types of variables:\n",
        "\n",
        "- **Continuous variables**  \n",
        "  Numeric measurements on a (more or less) continuous scale.  \n",
        "  Examples: `BMI`, `SBP`, `energy_kcal`, `fruit_veg_g_d`.\n",
        "\n",
        "- **Categorical variables (nominal)**  \n",
        "  Categories without an inherent order.  \n",
        "  Examples: `sex`, `SES_class`, `smoking_status`.\n",
        "\n",
        "- **Ordinal variables**  \n",
        "  Categories with a meaningful order, but without fixed distances between levels.  \n",
        "  Examples: `IMD_quintile` (1 = most deprived, 5 = least deprived), `physical_activity` (`low` / `moderate` / `high`).\n",
        "\n",
        "Later, in the workbook on sampling and representativeness, we will use these variable types to compare our synthetic FB2NEP cohort to reference surveys (such as NHANES). Here we focus on:\n",
        "\n",
        "- how different types of variables are **stored** and **summarised** in Python,  \n",
        "- what happens when we **encode** answers into numbers, and  \n",
        "- how we can already spot some problems just from the way data are coded."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0a47349",
      "metadata": {},
      "source": [
        "### UK Socio-Economic Status (SES) Classification – A Short Guide\n",
        "\n",
        "In UK public health and survey research, socio-economic status is often measured using the **NRS Social Grades**.  \n",
        "(NRS: National Readership Survey) They are widely used in national surveys, market research, and sometimes in epidemiology.\n",
        "\n",
        "#### 1. The Six NRS Social Grades\n",
        "\n",
        "| Grade | Meaning                                      | Typical occupations                                 |\n",
        "|-------|----------------------------------------------|-----------------------------------------------------|\n",
        "| **A** | Higher managerial, administrative, professional | CEOs, senior civil servants   |\n",
        "| **B** | Intermediate managerial, administrative, professional | Teachers, mid-level managers, engineers         |\n",
        "| **C1** | Supervisory, clerical, junior managerial/professional | Office staff, technicians                      |\n",
        "| **C2** | Skilled manual workers                      | Electricians, plumbers, carpenters                   |\n",
        "| **D** | Semi-skilled & unskilled manual workers       | Factory workers, delivery drivers                    |\n",
        "| **E** | Casual/lowest-grade workers, unemployed, pensioners | Long-term unemployed, some retirees             |\n",
        "\n",
        "These grades correlate with income, education, and job security — but they are not identical to any one of those.\n",
        "\n",
        "#### 2. The Two-Level System: ABC1 vs C2DE\n",
        "\n",
        "Many surveys collapse the six groups into two wider bands:\n",
        "\n",
        "- **ABC1**: higher or intermediate SES (A + B + C1)  \n",
        "- **C2DE**: lower SES (C2 + D + E)\n",
        "\n",
        "This simplified classification is the one used in the FB2NEP synthetic dataset (`SES_class`).\n",
        "\n",
        "#### 3. Strengths and Limitations\n",
        "\n",
        "**Strengths**\n",
        "- Simple, widely recognised, consistently used in UK surveys.\n",
        "- Shows clear associations with health behaviours and outcomes.\n",
        "\n",
        "**Limitations**\n",
        "- Coarse: mixes diverse occupations within broad categories.\n",
        "- Not portable outside the UK (occupation structures differ).\n",
        "- Based on *occupation*, which is awkward for students, retirees, carers, and precarious workers.\n",
        "- Does not map neatly to education or income.\n",
        "\n",
        "#### 4. Harmonisation Issues Across Datasets (Education, Income, Occupation)\n",
        "\n",
        "SES looks deceptively simple, but different datasets measure **different things**:\n",
        "\n",
        "- **NHANES (US)** uses *education* (≤ high school / some college / college+).\n",
        "- **NDNS (UK)** often uses education or income *alongside* NRS social grade.\n",
        "- **EPIC** and **UK Biobank** use mixtures of *occupation*, *education*, *income*, *area-level deprivation*.\n",
        "- **FB2NEP** uses *occupation-based social grades* (ABC1 / C2DE).\n",
        "- **International surveys** (OECD, WHO STEPS, Eurostat) usually use education because occupation and income do not translate across countries.\n",
        "\n",
        "This immediately creates problems for harmonisation.\n",
        "\n",
        "##### Why SES ≠ education ≠ income ≠ occupation\n",
        "\n",
        "SES is a **latent construct** — an underlying social position that cannot be measured directly.  \n",
        "Different operationalisations capture different aspects:\n",
        "\n",
        "- **Education** → long-term human capital, cognitive resources, health literacy.  \n",
        "- **Income** → current material resources and capacity to purchase goods.  \n",
        "- **Occupation** → job security, working conditions, prestige, social capital.  \n",
        "- **Area-level deprivation** → neighbourhood environment, access to services.\n",
        "\n",
        "These correlate, but not perfectly.  \n",
        "> Example: a highly educated PhD student may have low income; a long-serving electrician may earn more than a junior academic but be coded as C2, not ABC1.\n",
        "\n",
        "Using one variable to stand in for SES always loses information.\n",
        "\n",
        "##### Why the UK is unusual\n",
        "\n",
        "The UK has a long-standing, highly standardised **occupation-based SES system**:\n",
        "\n",
        "- **NRS Social Grades (A–E)**, created for media and market research, became widely used in public health research.\n",
        "- It maps occupation → social class → purchasing power in a historically industrial society.\n",
        "- It remains deeply embedded in UK survey infrastructure (ONS, NDNS, IPSOS, BBC, etc.).\n",
        "\n",
        "This is unusual internationally:\n",
        "\n",
        "- Most countries **do not** have a national occupation-based SES scale.\n",
        "- Education is the default SES variable in the US, EU, and WHO datasets because it is the most stable and portable across contexts.\n",
        "- Occupations, job structures and prestige systems differ too much between countries to harmonise consistently.\n",
        "\n",
        "Thus, using ABC1/C2DE outside the UK is difficult.\n",
        "\n",
        "##### What happens when two SES systems must be aligned?\n",
        "\n",
        "Any harmonisation requires **strong assumptions**.  \n",
        "Typical problems:\n",
        "\n",
        "- **Different constructs**: NHANES education ≠ UK NRS grades.  \n",
        "- **Different number of categories**: one is binary (ABC1/C2DE), one has three or six categories.  \n",
        "- **Different conceptual meaning**: \"College+\" is not equivalent to \"professional/managerial\".  \n",
        "- **Non-monotonic relationships**: more education ≠ higher job grade in every case.\n",
        "\n",
        "Example mismatches:\n",
        "- A retired senior civil servant → NRS A/B but education may be “≤ High school”.\n",
        "- A university graduate in a temporary low-paid job → college+ + C2 or D.\n",
        "- A tradesperson with high income → C2 but with higher income than many ABC1 workers.\n",
        "\n",
        "##### Implications for analysis\n",
        "\n",
        "Harmonisation is always an approximation.  \n",
        "When aligning SES across datasets:\n",
        "\n",
        "- **Be explicit** about the mapping rules you apply.  \n",
        "- **Check frequencies** and identify categories that map poorly.  \n",
        "- **Document data loss** (e.g. collapsing categories removes nuance).  \n",
        "- **Acknowledge uncertainty** introduced by any recoding.  \n",
        "- **Perform sensitivity analyses** where possible (e.g., different mapping schemes).\n",
        "\n",
        "Teaching takeaway:  \n",
        "*SES is a theoretical construct, not a variable.  \n",
        "Every dataset measures it differently.  \n",
        "Harmonisation therefore requires judgement, transparency, and a clear statement of limitations.*\n",
        "\n",
        "\n",
        "#### 5. Takeaway\n",
        "\n",
        "SES is not a single “true” attribute.  \n",
        "Different countries, surveys and traditions measure it differently.  \n",
        "For cross-dataset comparisons (e.g. NHANES vs FB2NEP), SES must be **translated** with care and the uncertainties should be stated clearly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a82d328",
      "metadata": {},
      "source": [
        "### Excursion: Index of Multiple Deprivation (IMD)\n",
        "\n",
        "\n",
        "**Index of Multiple Deprivation (IMD)** is the main *area-based* measure of deprivation used in England.  \n",
        "It does **not** describe an individual’s SES, but the **deprivation level of the small area** where they live.\n",
        "\n",
        "---\n",
        "\n",
        "##### 1. What IMD measures\n",
        "\n",
        "IMD combines **seven domains** of deprivation into a single index:\n",
        "\n",
        "1. **Income**  \n",
        "2. **Employment**  \n",
        "3. **Education, skills and training**  \n",
        "4. **Health and disability**  \n",
        "5. **Crime**  \n",
        "6. **Barriers to housing and services**  \n",
        "7. **Living environment**\n",
        "\n",
        "Each small area (Lower Layer Super Output Area, LSOA; ~1,500 people) receives:\n",
        "\n",
        "- a **rank** (1 = most deprived area in England),  \n",
        "- and derived **deciles** or **quintiles**.\n",
        "\n",
        "In FB2NEP we use **IMD quintiles**, where:\n",
        "\n",
        "- **1 = most deprived**,  \n",
        "- **5 = least deprived**.\n",
        "\n",
        "---\n",
        "\n",
        "##### 2. IMD vs individual SES\n",
        "\n",
        "IMD is **area-level**; SES (such as NRS social grade or education) is usually **individual-level**.\n",
        "\n",
        "They capture related but different aspects:\n",
        "\n",
        "- IMD reflects the **context** of a neighbourhood  \n",
        "  (local income, employment, environment, access to services, crime).  \n",
        "- SES reflects an individual’s **social position**  \n",
        "  (education, occupation, income, security).\n",
        "\n",
        "Examples:\n",
        "\n",
        "- A highly educated person may live in an IMD 1 area (cheap housing in a deprived neighbourhood).  \n",
        "- A low-income person may live in an IMD 4–5 area (long-term tenant in a relatively affluent area).\n",
        "\n",
        "**Key point:** IMD is very useful for understanding **health inequalities and neighbourhood effects**,  \n",
        "but it must not be treated as “the same thing” as individual SES.\n",
        "\n",
        "---\n",
        "\n",
        "##### 3. Why IMD appears in FB2NEP\n",
        "\n",
        "Many UK cohort studies and surveys (e.g. NDNS, UK Biobank, some cancer registries) link IMD to participants via postcode.  \n",
        "Typical uses include:\n",
        "\n",
        "- describing the **deprivation profile** of the cohort,  \n",
        "- studying **gradients** in risk factors and disease by area-level deprivation,  \n",
        "- adjusting for area-level deprivation as a potential **confounder**.\n",
        "\n",
        "FB2NEP mirrors this practice by including `IMD_quintile`:\n",
        "\n",
        "- It lets us explore **inequalities** in diet and health,  \n",
        "- and it sets up later Public Health exercises where IMD plays a central role.\n",
        "\n",
        "---\n",
        "\n",
        "##### 4. Practical reminders for analysis\n",
        "\n",
        "- Treat IMD as an **ordered categorical** variable (e.g. quintiles), not as a precise continuous scale.  \n",
        "- Be clear in write-ups that IMD is **area-based**, not a personal SES measure.  \n",
        "- Consider showing results by **both** individual SES (e.g. ABC1/C2DE) **and** IMD where possible.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab7253b0",
      "metadata": {},
      "source": [
        "### Excursion: Physical Activity – Why Categories Are Vague (and Why It Matters)\n",
        "\n",
        "Physical activity is **essential** in nutritional epidemiology, yet it is one of the **least precisely measured** variables in any dataset.  \n",
        "Even “good” surveys struggle because *activity is multi-dimensional* and hard to summarise in a single score.\n",
        "\n",
        "---\n",
        "\n",
        "##### 1. Why physical activity is hard to measure\n",
        "\n",
        "Physical activity varies by:\n",
        "\n",
        "- **Intensity** (light, moderate, vigorous)  \n",
        "- **Type** (walking, cycling, work-related, leisure, sport, chores)  \n",
        "- **Duration**  \n",
        "- **Frequency**  \n",
        "- **Context** (commuting, occupation, exercise, childcare)\n",
        "\n",
        "This creates an enormous range of behaviours that cannot easily be captured by simple categories.\n",
        "\n",
        "---\n",
        "\n",
        "##### 2. How surveys measure activity\n",
        "\n",
        "Most population studies rely on **self-report**, for example:\n",
        "\n",
        "- “How many minutes per week of moderate physical activity do you do?”  \n",
        "- “How often do you walk for at least 10 minutes?”  \n",
        "- “How active is your job?”  \n",
        "- Likert scales such as *low / moderate / high*.\n",
        "\n",
        "More detailed instruments exist (IPAQ, GPAQ), but they still rely on participant recall and judgement.  \n",
        "Even objectively measured PA (accelerometers, wearables) must be **translated into categories**, and the choice of cut-points affects results.\n",
        "\n",
        "---\n",
        "\n",
        "##### 3. What FB2NEP uses (and why)\n",
        "\n",
        "FB2NEP includes a variable:\n",
        "\n",
        "- **`physical_activity`** = `\"low\"`, `\"moderate\"`, `\"high\"`\n",
        "\n",
        "This is typical in cohort studies where detailed accelerometer data are not available.\n",
        "\n",
        "However, these categories are:\n",
        "\n",
        "- **Vague**: “moderate” for one person may be “vigorous” for another.  \n",
        "- **Self-assessed**: depends on how active participants *feel*.  \n",
        "- **Context-dependent**: a manual worker and a sedentary office worker with the same walking minutes may not classify themselves the same way.\n",
        "\n",
        "In other words:  \n",
        "> *These categories provide a rough indicator of activity level, useful for broad comparisons but not precise enough to infer true energy expenditure.*\n",
        "\n",
        "---\n",
        "\n",
        "##### 4. Common problems in analysis\n",
        "\n",
        "1. **Non-comparability across surveys**  \n",
        "   - NHANES uses MET-minutes.  \n",
        "   - NDNS uses questionnaire-based categorisation.  \n",
        "   - UK Biobank uses a mixture (IPAQ-like questions + accelerometer subsample).  \n",
        "   - EPIC uses a 4-level Cambridge index.\n",
        "\n",
        "   These systems are **not equivalent**.\n",
        "\n",
        "2. **Categorisation introduces information loss**  \n",
        "   - Collapsing minutes, intensity, and context into one label removes detail.  \n",
        "   - “Moderate” may hide large differences in actual activity.\n",
        "\n",
        "3. **Cut-off sensitivity**  \n",
        "   - If “moderate” is defined differently across studies, results are not directly comparable.\n",
        "\n",
        "4. **Residual confounding**  \n",
        "   - PA categories are too crude to fully capture lifestyle differences  \n",
        "     (e.g. fitness, occupation, active commuting).\n",
        "\n",
        "---\n",
        "\n",
        "##### 5. Why this matters for nutritional epidemiology\n",
        "\n",
        "Physical activity is a major confounder for:\n",
        "\n",
        "- Energy intake  \n",
        "- Obesity  \n",
        "- Cardiovascular risk  \n",
        "- Metabolic markers  \n",
        "- Sedentary behaviour  \n",
        "- Diet–disease associations\n",
        "\n",
        "Using crude PA categories increases **measurement error**, which tends to:\n",
        "\n",
        "- **Bias effect estimates toward the null**,  \n",
        "- **Inflate residual confounding**,  \n",
        "- Make PA look “less important” than it is.\n",
        "\n",
        "---\n",
        "\n",
        "##### 6. Takeaway\n",
        "\n",
        "- Physical activity categories are **useful**, but **imprecise**.  \n",
        "- Never over-interpret “low/moderate/high” as exact physiological measures.  \n",
        "- When comparing datasets, check how PA was measured and consider harmonisation issues.  \n",
        "- If possible, perform **sensitivity analyses** using alternative cut-points.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "quick-look-types",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.1 Quick look at the synthetic cohort and variable types\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "# Show the first 5 rows\n",
        "display(df.head())\n",
        "\n",
        "# Show the data types of the first few columns\n",
        "df.dtypes.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "var-type-summaries",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1.2 Examples of how we summarise different variable types\n",
        "\n",
        "# Continuous example: BMI\n",
        "if \"BMI\" in df.columns:\n",
        "    print(\"BMI – continuous variable\")\n",
        "    display(df[\"BMI\"].describe())\n",
        "\n",
        "# Categorical example: sex\n",
        "if \"sex\" in df.columns:\n",
        "    print(\"\\nsex – categorical (nominal)\")\n",
        "    print(df[\"sex\"].value_counts(dropna=False))\n",
        "\n",
        "# Ordinal example: IMD_quintile\n",
        "if \"IMD_quintile\" in df.columns:\n",
        "    print(\"\\nIMD_quintile – stored as numbers, but conceptually ordered categories\")\n",
        "    print(df[\"IMD_quintile\"].value_counts(dropna=False).sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "how-to-use-types",
      "metadata": {},
      "source": [
        "### 1.3 How we (should) use different types\n",
        "\n",
        "- For **continuous variables** we normally use summaries such as *mean*, *standard deviation*,\n",
        "  histograms, boxplots, and regression models with the variable on its original scale.\n",
        "\n",
        "- For **categorical variables** we usually use *counts* and *proportions*, and cross-tabulations\n",
        "  (contingency tables), for example `smoking_status × CVD_incident`.\n",
        "\n",
        "- For **ordinal variables**, we technically have two options:\n",
        "\n",
        "  1. **Treat them as ordered categories**  \n",
        "     (e.g. proportional-odds models, cumulative logit models, or ordered bar charts).  \n",
        "     This respects the fact that the categories have an order *but not a measurable distance*.\n",
        "\n",
        "  2. **Code them as 0/1/2/3 and analyse them as if they were continuous**  \n",
        "     (e.g. using them in linear regression).\n",
        "\n",
        "  ⚠️ **This second option is risky** because it quietly assumes:\n",
        "     - the “gap” between *low → moderate* is the same size as *moderate → high*;  \n",
        "     - and that those distances are meaningful on a numeric scale.\n",
        "\n",
        "     These assumptions are almost never justified.\n",
        "\n",
        "     Treating ordinal scales as continuous can:\n",
        "     - distort effect sizes,  \n",
        "     - produce misleading trends,  \n",
        "     - violate model assumptions,  \n",
        "     - and give regression coefficients that look precise but have no real-world meaning.\n",
        " \n",
        "     > *It works by accident, not by principle.*\n",
        "\n",
        "**Best practice:**  \n",
        "Use ordinal models when possible; if you collapse the scale to treat it as continuous, justify it clearly and perform sensitivity checks.\n",
        "\n",
        "\n",
        "For this module we keep a simple rule of thumb:\n",
        "\n",
        "> Ordinal variables are *not automatically* continuous.  \n",
        "> If you code them as numbers, you must still think about whether treating\n",
        "> \"low → moderate → high\" as evenly spaced is sensible for your question.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36f159e7",
      "metadata": {},
      "source": [
        "### 1.4 Simple validation example: smoking and CVD\n",
        "\n",
        "As a quick **sanity check**, we can look at how often incident cardiovascular disease (CVD) occurs in different **smoking categories**.\n",
        "\n",
        "- `smoking_status` is a **categorical exposure** (for example, never / former / current).\n",
        "- `CVD_incident` is a **binary outcome** (0 = no event, 1 = event).\n",
        "\n",
        "A natural question is:\n",
        "\n",
        "> *“Is incident CVD more common in some smoking groups than others?”*\n",
        "\n",
        "To explore this, we can use `pandas.crosstab` with `normalize=\"index\"`:\n",
        "\n",
        "- Each **row** corresponds to one smoking category.\n",
        "- Each **cell** is the **proportion** of participants in that smoking group with / without incident CVD.\n",
        "- Rows therefore sum to 1 (100%).\n",
        "\n",
        "This does **not** prove causality, and it ignores confounders (for example, age, sex, SES),  \n",
        "but it is a very useful descriptive check:\n",
        "\n",
        "- Does the pattern roughly match what we expect (higher CVD in current smokers than never smokers)?  \n",
        "- Are there any obviously strange values (for example, zero events in a large group)?\n",
        "\n",
        "In the next cell we compute and display this row-normalised cross-tabulation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "contingency-example",
      "metadata": {},
      "outputs": [],
      "source": [
        "if {\"smoking_status\", \"CVD_incident\"}.issubset(df.columns):\n",
        "    tab = pd.crosstab(df[\"smoking_status\"], df[\"CVD_incident\"], normalize=\"index\")\n",
        "    print(\"Proportion with incident CVD by smoking status:\")\n",
        "    display(tab)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a138683",
      "metadata": {},
      "source": [
        "### 1.5 Making ordinal variables explicit in the data\n",
        "\n",
        "Some variables in `df` are **inherently ordered**, even though they are stored as numbers or plain strings:\n",
        "\n",
        "- `IMD_quintile`: 1 (most deprived) → 5 (least deprived).  \n",
        "- `physical_activity`: `\"low\"` → `\"moderate\"` → `\"high\"`.\n",
        "\n",
        "If we leave them as ordinary integers/strings, pandas and most modelling functions will treat them either as:\n",
        "\n",
        "- **purely categorical** (no order at all), or  \n",
        "- **continuous** (for example, using 1–5 as if the gaps were equal).\n",
        "\n",
        "Both can be misleading:\n",
        "\n",
        "- Treating them as **unordered categories** throws away the ranking information.  \n",
        "- Treating them as **continuous** quietly assumes that the “distance” from 1→2 is the same as 4→5, which is rarely justified.\n",
        "\n",
        "A better approach is to mark them explicitly as **ordered categorical variables**.  \n",
        "This preserves the ranking (1 < 2 < … < 5; low < moderate < high) without pretending that the gaps are equal.\n",
        "\n",
        "In the next cell we:\n",
        "\n",
        "- create `IMD_quintile_ord` and `physical_activity_ord` as ordered `Categorical` variables;  \n",
        "- keep the original columns so you can see both side by side.\n",
        "\n",
        "Later, when we model these variables, we can use methods appropriate for ordered data (for example, ordered bar plots, stratified summaries, or proportional-odds models), rather than treating them as plain numbers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ord-categorical-example",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "if \"IMD_quintile\" in df.columns:\n",
        "    df[\"IMD_quintile_ord\"] = pd.Categorical(\n",
        "        df[\"IMD_quintile\"],\n",
        "        categories=[1, 2, 3, 4, 5],\n",
        "        ordered=True,\n",
        "    )\n",
        "\n",
        "if \"physical_activity\" in df.columns:\n",
        "    df[\"physical_activity_ord\"] = pd.Categorical(\n",
        "        df[\"physical_activity\"],\n",
        "        categories=[\"low\", \"moderate\", \"high\"],\n",
        "        ordered=True,\n",
        "    )\n",
        "\n",
        "cols_to_show = [\n",
        "    c for c in [\"IMD_quintile\", \"IMD_quintile_ord\", \"physical_activity\", \"physical_activity_ord\"]\n",
        "    if c in df.columns\n",
        "]\n",
        "\n",
        "if cols_to_show:\n",
        "    display(df[cols_to_show].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "data-pipelines",
      "metadata": {},
      "source": [
        "## 2. Data collection pipelines\n",
        "\n",
        "In nutritional epidemiology, data usually come from several sources that are linked together:\n",
        "\n",
        "- **Questionnaires and interviews** (for example, food frequency questionnaires, 24-hour recalls, lifestyle questionnaires).\n",
        "- **Laboratory measurements** (for example, blood biomarkers, urinary biomarkers).\n",
        "- **Clinical examinations** (for example, blood pressure, anthropometry).\n",
        "- **Registers and administrative data** (for example, hospital episode statistics, cancer registries, mortality data).\n",
        "- **Public datasets and surveys** (for example, NHANES in the United States, NDNS in the United Kingdom).\n",
        "\n",
        "Typical steps in a data collection pipeline are:\n",
        "\n",
        "1. **Sampling and recruitment** of participants.\n",
        "2. **Baseline data collection**:\n",
        "   - Questionnaires completed on paper, online, or via interview.\n",
        "   - Clinical and anthropometric measurements.\n",
        "   - Biospecimen collection for later laboratory analysis.\n",
        "3. **Follow-up data collection**:\n",
        "   - Repeat questionnaires or clinic visits.\n",
        "   - Linkage to health registers to obtain information on disease outcomes.\n",
        "4. **Data entry, coding and merging**:\n",
        "   - Scanning or manual entry of questionnaires.\n",
        "   - Coding of free-text responses.\n",
        "   - Merging laboratory, questionnaire and register data using a unique participant identifier.\n",
        "\n",
        "The synthetic FB2NEP dataset represents a **merged cohort** where these steps have already taken place. The underlying logic, however, is the same as in real-world studies such as NHANES or NDNS.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "740b171b",
      "metadata": {},
      "source": [
        "### 2.1 Units and harmonisation\n",
        "\n",
        "When combining or comparing datasets, we must pay attention to **units** and **coding schemes**:\n",
        "\n",
        "- Blood lipids: mmol/L (UK, Europe) vs mg/dL (US).\n",
        "- Height: centimetres vs inches.\n",
        "- Education and SES: different qualification systems across countries.\n",
        "- Physical activity: self-reported categories vs device-based measures.\n",
        "\n",
        "Before merging or comparing datasets we should always check:\n",
        "\n",
        "1. Units and reference ranges (for example, SBP in mmHg vs kPa).  \n",
        "2. Coding manuals for questionnaires (for example, education categories).  \n",
        "3. Whether local scores (for example, deprivation indices) are comparable at all.\n",
        "\n",
        "In later workbooks, when we compare FB2NEP to NHANES or NDNS, we will see that harmonisation sometimes requires judgement and inevitably involves some information loss."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "coding-info-loss",
      "metadata": {},
      "source": [
        "## 3. Coding and information loss\n",
        "\n",
        "When we turn real-world phenomena into variables, we always **lose information** – long before we fit any models.\n",
        "\n",
        "Examples:\n",
        "\n",
        "- Turning height and weight into **BMI** loses information about body shape.  \n",
        "  Two people with very different height and weight can have the *same* BMI.\n",
        "- Turning continuous BMI into three categories (for example,\n",
        "  *normal / overweight / obese*) throws away all variation **within** each band.\n",
        "- Turning detailed income into a few SES categories (`ABC1` vs `C2DE`) hides\n",
        "  differences *within* each broad class.\n",
        "\n",
        "Why do we code and collapse variables?\n",
        "\n",
        "> *Coding* refers to the systematic assignment of numerical or categorical codes to raw data values (e.g., converting BMI into obesity categories such as 0 = underweight, 1 = normal, 2 = overweight, 3 = obese) to facilitate statistical analysis, grouping, or modelling.\n",
        "\n",
        "- To shorten questionnaires.\n",
        "- To make models simpler and more stable.\n",
        "- To produce tables that fit on one slide or in a paper.\n",
        "\n",
        "The trade-off is:\n",
        "\n",
        "> More coding and categorisation → simpler communication,  \n",
        "> but **less information** and sometimes **more bias**.\n",
        "\n",
        "In practice, we should:\n",
        "\n",
        "- keep the **rawest sensible version** of each variable;\n",
        "- document every coding step;\n",
        "- think about what has been **lost** at each stage."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e70f21ff",
      "metadata": {},
      "source": [
        "### 3.1 Example: collapsing continuous BMI into categories\n",
        "\n",
        "BMI itself is already a **derived** measure:\n",
        "\n",
        "- It combines *height* and *weight* into a single number (`kg/m²`);\n",
        "- It does **not** distinguish between muscle and fat mass;\n",
        "- It treats all people with the same BMI as equivalent, even if their body\n",
        "  composition is very different.\n",
        "\n",
        "On top of that, we often **categorise** BMI:\n",
        "\n",
        "- “normal weight”, “overweight”, “obese”, sometimes with more bands;\n",
        "- convenient for guidelines and tables;\n",
        "- but it discards differences within each band  \n",
        "  (for example, BMI 30.1 vs 39.9 are both just “obese”).\n",
        "\n",
        "> **Please note**  \n",
        "> BMI cut-off points associated with metabolic risk differ across ethnic groups.  \n",
        "> Several populations develop type 2 diabetes at **lower BMI** than White populations.\n",
        "\n",
        "### Ethnic-specific BMI thresholds for equivalent diabetes risk\n",
        "\n",
        "Using a cohort of 1.47 million adults in England, Caleyachetty et al. (2021) compared the  \n",
        "BMI level at which different ethnic groups have the **same age- and sex-adjusted incidence**  \n",
        "of type 2 diabetes as White adults at **BMI 30 kg/m²**.\n",
        "\n",
        "| Ethnic group | BMI associated with equivalent diabetes risk | 95% CI |\n",
        "|--------------|----------------------------------------------|--------|\n",
        "| **White**        | 30.0 kg/m² (reference)                       | –      |\n",
        "| **South Asian**  | **23.9 kg/m²**                               | 23.6–24.0 |\n",
        "| **Black**        | **28.1 kg/m²**                               | 28.0–28.4 |\n",
        "| **Chinese**      | **26.9 kg/m²**                               | 26.7–27.2 |\n",
        "| **Arab**         | **26.6 kg/m²**                               | 26.5–27.0 |\n",
        "\n",
        "**Key teaching point:**  \n",
        "A BMI of 30 kg/m² does **not** represent the same metabolic risk across all ethnicities.  \n",
        "For some groups (notably South Asian and Chinese populations), clinically relevant risk  \n",
        "appears at **much lower BMI values**.\n",
        "\n",
        "*Source:*  \n",
        "Caleyachetty R. et al. *Lancet Diabetes & Endocrinology* 2021;9:419–26.  \n",
        "\n",
        "\n",
        "In the code below we:\n",
        "\n",
        "1. Start from continuous BMI.  \n",
        "2. Create three broad categories using `pd.cut`.  \n",
        "3. Compare the summary of the original BMI distribution with the counts in each category.\n",
        "\n",
        "This is purely **illustrative** – it shows how easy it is to throw away information.\n",
        "In later weeks, we will discuss when categorisation might be useful and when it is\n",
        "better to keep BMI continuous (or use other measures such as waist circumference)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9120004",
      "metadata": {},
      "source": [
        "#### 3.1.1 Visual example: same BMI, different body composition\n",
        "\n",
        "BMI cannot distinguish between **fat mass** and **muscle mass**.\n",
        "\n",
        "In the illustration below, both individuals have (hypothetically) the **same BMI**,\n",
        "but very different body composition:\n",
        "\n",
        "- one predominantly muscular,\n",
        "- one with higher body fat.\n",
        "\n",
        "![Two individuals with identical BMI but different body composition](../_assets/bmi_same_bmi_diff_bodyshape.png)\n",
        "\n",
        "This is why BMI is useful as a **crude screening tool**, but not a perfect\n",
        "measure of adiposity in individuals.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bmi-categories-example",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.1 Example: collapsing continuous BMI into categories\n",
        "\n",
        "if \"BMI\" in df.columns:\n",
        "    bmi = df[\"BMI\"].copy()\n",
        "\n",
        "    # Very simple categories for illustration only\n",
        "    bmi_cat = pd.cut(\n",
        "        bmi,\n",
        "        bins=[0, 25, 30, np.inf],\n",
        "        labels=[\"normal\", \"overweight\", \"obese\"],\n",
        "        right=False,\n",
        "    )\n",
        "\n",
        "    print(\"Original BMI (continuous) summary:\")\n",
        "    display(bmi.describe())\n",
        "\n",
        "    print(\"\\nBMI categories (illustrative):\")\n",
        "    print(bmi_cat.value_counts(dropna=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0df13c1",
      "metadata": {},
      "source": [
        "#### 3.2 Self-reported height and weight\n",
        "\n",
        "Many large studies (including some national surveys) use **self-reported** height\n",
        "and weight instead of measured values.\n",
        "\n",
        "Typical patterns:\n",
        "\n",
        "- People tend to **over-report height**.\n",
        "- People tend to **under-report weight**.\n",
        "- The bias is not random – it often depends on sex, age, and actual body size.\n",
        "\n",
        "Consequences:\n",
        "\n",
        "- BMI from self-report is usually **biased downwards**.\n",
        "- Misclassification across BMI categories (normal / overweight / obese) is common.\n",
        "- Associations between BMI and health outcomes can be **biased** if we ignore\n",
        "  this measurement error.\n",
        "\n",
        "For teaching purposes, it is helpful to remember that:\n",
        "\n",
        "> BMI combines two measured variables (height, weight)  \n",
        "> and those measurements themselves may be biased.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "implausible-values",
      "metadata": {},
      "source": [
        "## 4. Identifying implausible or inconsistent values\n",
        "\n",
        "Even carefully collected data may contain values that are *implausible* or *wrong*.\n",
        "Examples include:\n",
        "\n",
        "- Anthropometric values outside physiological limits (for example, BMI < 10 kg/m²).\n",
        "- Blood pressure values that are extremely low or high.\n",
        "- Energy intakes that are incompatible with life over the long term.\n",
        "- Men who are recorded as being “post-menopausal”.\n",
        "\n",
        "In practice we define **simple rules** to flag such values for review, and in some cases to exclude them from analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "impl-bmi",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.1 Example: BMI range check\n",
        "#\n",
        "# These cut-offs are illustrative. In a real study they should be\n",
        "# chosen with clinical input and clear documentation.\n",
        "\n",
        "if \"BMI\" in df.columns:\n",
        "    print(\"Summary of BMI:\")\n",
        "    display(df[\"BMI\"].describe())\n",
        "\n",
        "    implausible_bmi = df[(df[\"BMI\"] < 10) | (df[\"BMI\"] > 70)]\n",
        "    print(f\"Number of participants with BMI < 10 or > 70: {len(implausible_bmi)}\")\n",
        "    display(implausible_bmi.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bp-check",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.2 Example: SBP (systolic blood pressure) range check\n",
        "\n",
        "if \"SBP\" in df.columns:\n",
        "    print(\"Summary of SBP:\")\n",
        "    display(df[\"SBP\"].describe())\n",
        "\n",
        "    implausible_sbp = df[(df[\"SBP\"] < 70) | (df[\"SBP\"] > 260)]\n",
        "    print(f\"Number of participants with SBP < 70 or > 260 mmHg: {len(implausible_sbp)}\")\n",
        "    display(implausible_sbp.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bmi-hist",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.3 Distribution of BMI – visual check\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "if \"BMI\" in df.columns:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    df[\"BMI\"].hist(bins=30)\n",
        "    plt.xlabel(\"BMI (kg/m²)\")\n",
        "    plt.ylabel(\"Number of participants\")\n",
        "    plt.title(\"Distribution of BMI – initial check\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "goldberg-text",
      "metadata": {},
      "source": [
        "### 4.4 Energy Intake Plausibility and the Goldberg Cut-off\n",
        "\n",
        "In nutritional epidemiology, a recurring question is whether **reported energy intake (EI)** is\n",
        "compatible with the **energy a person is expected to expend**.  \n",
        "The **Goldberg cut-off** is a widely used, reproducible approach to detect *implausible*\n",
        "self-reported energy intakes.\n",
        "\n",
        "#### 1. Core idea\n",
        "\n",
        "The method compares:\n",
        "\n",
        "$$\n",
        "\\frac{\\text{EI}}{\\text{EE}}\n",
        "$$\n",
        "\n",
        "where **EE** is the *minimum* energy expenditure expected for that person.\n",
        "\n",
        "If the ratio is *too low*, the individual is likely to be an **under-reporter**.\n",
        "\n",
        "#### 2. Steps in the Goldberg method\n",
        "\n",
        "1. **Estimate Basal Metabolic Rate (BMR)**  \n",
        "   Usually via predictive equations (Schofield, Henry, or similar) using:\n",
        "   - age  \n",
        "   - sex  \n",
        "   - weight (and occasionally height)\n",
        "\n",
        "2. **Assume a minimum plausible Physical Activity Level (PAL)**  \n",
        "   A typical assumption is **PAL = 1.55** for a “sedentary to lightly active” lifestyle.  \n",
        "   This gives the minimum Total Energy Expenditure (TEE):\n",
        "\n",
        "$$\n",
        "   \\text{TEE}_{\\min} = \\text{BMR} \\times \\text{PAL}\n",
        "$$\n",
        "\n",
        "3. **Compute the Goldberg ratio**\n",
        "\n",
        "$$\n",
        "   r = \\frac{\\text{Reported EI}}{\\text{TEE}_{\\min}}\n",
        "$$\n",
        "\n",
        "4. **Compare the ratio to a cut-off**\n",
        "\n",
        "   A common lower limit is **0.76–0.80**, derived by combining:\n",
        "   - day-to-day variation in energy intake,\n",
        "   - variation in BMR prediction,\n",
        "   - sampling duration.\n",
        "\n",
        "   If $$ r < \\text{cut-off} $$, the intake is considered **implausibly low**.\n",
        "\n",
        "#### 3. Interpretation\n",
        "\n",
        "The rule does *not* say the individual is deliberately misreporting.  \n",
        "It indicates that the **reported intake is statistically incompatible** with sustaining\n",
        "basic physiological requirements over time.\n",
        "\n",
        "Examples:\n",
        "- A reported EI of **900 kcal/day** for a healthy adult is implausible.  \n",
        "- A physically active person reporting 1,200 kcal/day may also be flagged.\n",
        "\n",
        "#### 4. Why the Goldberg cut-off is widely used\n",
        "\n",
        "- **Transparent** and fully formula-based.  \n",
        "- **Simple** and implementable in any dataset.  \n",
        "- **Consistent** across studies.  \n",
        "- Helps identify **outliers** before modelling.\n",
        "\n",
        "However, the method is designed for population-level plausibility screening, **not** as a\n",
        "diagnostic tool for individual behaviour.\n",
        "\n",
        "---\n",
        "\n",
        "### 4.5 Limitations of the Goldberg Cut-off\n",
        "\n",
        "Although influential, the Goldberg approach has important limitations:\n",
        "\n",
        "#### (a) Strong assumptions about PAL  \n",
        "Using a fixed PAL (for example 1.55) ignores the wide variation in physical activity\n",
        "between individuals.  \n",
        "TEE may be substantially higher or lower than assumed, causing:\n",
        "- *false positives* (flagged as under-reporting but plausible),  \n",
        "- *false negatives* (severe under-reporting may not be flagged if activity is low).\n",
        "\n",
        "#### (b) BMR prediction error  \n",
        "Predictive equations for BMR introduce error:\n",
        "- ±5–10% for many individuals,\n",
        "- larger for those with atypical body composition.\n",
        "\n",
        "If BMR is misestimated, the Goldberg ratio becomes misleading.\n",
        "\n",
        "#### (c) One-day (or few-day) intake is **not** habitual intake  \n",
        "Short-term 24-h recalls show **large day-to-day variation**, making the ratio unstable.\n",
        "\n",
        "#### (d) Cannot distinguish *intentional dieting*  \n",
        "Low reported intakes may reflect:\n",
        "- short-term restriction,\n",
        "- illness,\n",
        "- poor recall,\n",
        "- dieting behaviour.\n",
        "\n",
        "The cut-off treats all as “implausible”.\n",
        "\n",
        "#### (e) Systematic bias in self-reporting  \n",
        "Energy misreporting is **not random**:\n",
        "- overweight individuals tend to under-report energy, especially snacks and high-fat foods;\n",
        "- some demographic groups systematically under- or over-report.\n",
        "\n",
        "Thus the Goldberg decision can itself **introduce bias**, for example:\n",
        "- removing more participants with high BMI,\n",
        "- altering diet–BMI or diet–disease associations.\n",
        "\n",
        "This concern is highlighted in recent evaluation studies.\n",
        "\n",
        "---\n",
        "\n",
        "### 4.6 Recent evidence and critique\n",
        "\n",
        "A recent paper in *Nature Food* [Bajunaid et al., 2025](https://www.nature.com/articles/s43016-024-01089-5)\n",
        "**“Energy intake and expenditure in doubly labelled water studies worldwide”**  \n",
        "provides an updated perspective:\n",
        "\n",
        "- Doubly labelled water (DLW) studies show **large inter-individual variation in TEE**, wider than commonly assumed in Goldberg calculations.\n",
        "- Habitual EI is often **higher than self-reported**, but misreporting varies by age, sex, BMI and cultural context.\n",
        "- The study stresses that **physiological variation is larger** than the Goldberg framework assumes.\n",
        "- Therefore, using a universal PAL and narrow cut-offs may systematically misclassify valid data.\n",
        "\n",
        "This supports a broader consensus that:\n",
        "\n",
        "> The Goldberg cut-off is useful as a descriptive tool,  \n",
        "> but insufficient for high-stakes decisions (for example, excluding participants).\n",
        "\n",
        "---\n",
        "\n",
        "### Takeaway\n",
        "\n",
        "The Goldberg cut-off is a **useful first-pass plausibility screen**, but:\n",
        "\n",
        "- it rests on strong assumptions,\n",
        "- it is sensitive to prediction error,\n",
        "- and it can introduce bias if used uncritically.\n",
        "\n",
        "Modern datasets—with diverse populations, high variation in physical activity, and\n",
        "systematic misreporting—require **more nuanced approaches**, ideally supported by\n",
        "validation studies (for example, DLW data).\n",
        "\n",
        "In FB2NEP we therefore use the Goldberg principle to illustrate:\n",
        "\n",
        "- how plausibility checks work,\n",
        "- where modelling decisions come from,\n",
        "- and why epidemiological analyses require transparent assumptions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "energy-simple",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.5 Simple exploration of energy intake\n",
        "\n",
        "if \"energy_kcal\" in df.columns:\n",
        "    print(\"Summary of reported energy intake (kcal/d):\")\n",
        "    display(df[\"energy_kcal\"].describe())\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    df[\"energy_kcal\"].hist(bins=30)\n",
        "    plt.xlabel(\"Energy intake (kcal/day)\")\n",
        "    plt.ylabel(\"Number of participants\")\n",
        "    plt.title(\"Distribution of reported energy intake\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5155accc",
      "metadata": {},
      "source": [
        "## 4.5 Plausibility and scale: hippo vs mouse energy intake\n",
        "\n",
        "Think of **reported energy intake**:\n",
        "\n",
        "- A very small human reporting 15 000 kcal/day is *hippo-level* – probably implausible.\n",
        "- A large human reporting 600 kcal/day *long term* is *mouse-level* – probably implausible too.\n",
        "\n",
        "The FB2NEP dataset includes `energy_kcal`. When we look at its distribution we will:\n",
        "\n",
        "- check whether values lie in a broadly plausible human range, and  \n",
        "- remember that even plausible values can still be under- or over-reported.\n",
        "\n",
        "Later, you will encounter the **Goldberg cut-off**, which formalises this idea by comparing\n",
        "reported intake with estimated energy requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rare-values-text",
      "metadata": {},
      "source": [
        "## 5. Rare categories and “Prefer not to say”\n",
        "\n",
        "Questionnaires often include categories such as **“Prefer not to say”** or very rare\n",
        "responses. These raise practical questions:\n",
        "\n",
        "- Should they be combined with another category?\n",
        "- Should they be treated as missing data?\n",
        "- Do they indicate a problem with the question (for example, perceived sensitivity)?\n",
        "\n",
        "Some patterns can be **red flags**:\n",
        "\n",
        "- A question that is *consistently skipped* (many missing values) compared with others.  \n",
        "  → Possible misunderstanding, poor wording, or discomfort with the topic.\n",
        "- A single participant who answers “Prefer not to say” to almost everything.  \n",
        "  → Possible disengagement; their data may be low quality overall.\n",
        "- Systematic non-response to certain topics (for example, income, alcohol).  \n",
        "  → Missingness may be **MNAR** and needs careful handling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "770dc15e",
      "metadata": {},
      "source": [
        "### 5.1 Test questions and internal consistency\n",
        "\n",
        "Some questionnaires include one or two **test questions** to check whether\n",
        "participants are paying attention. Typical examples are:\n",
        "\n",
        "- “To show that you are paying attention, please select **‘strongly agree’** for this statement.”  \n",
        "- “For this question only, please tick **‘never’**.”  \n",
        "- “The colour of the sky on a clear day is… (please tick **‘blue’**).”\n",
        "\n",
        "Other examples are factual statements about well-known places such as:\n",
        "\n",
        "- “Wasilla, Alaska is in the continental United States — please select ‘Strongly disagree’.”\n",
        "- “Barrow, Alaska never receives snow — please select ‘Disagree’.”\n",
        "\n",
        "These items are widely used in survey-methods teaching because the correct\n",
        "answer is obvious, yet respondents who are not reading the questions carefully will fail them.\n",
        "\n",
        "\n",
        "If participants fail these items, their responses might be low quality.\n",
        "\n",
        "- This is common in **online surveys** and panel studies.\n",
        "- In large **epidemiological cohorts** the practice is less standard, but the *idea* is similar:\n",
        "  we want to detect obviously invalid or careless data.\n",
        "\n",
        "\n",
        "\n",
        "Instead of explicit test questions, cohort studies often rely on **internal consistency checks**, for example:\n",
        "\n",
        "- A participant reporting **“never drinks alcohol”** but also giving detailed answers about  \n",
        "  number of **glasses of wine per week** and **maximum units on one occasion**.  \n",
        "- Reporting **0 minutes of physical activity per week**, but also stating that they **cycle to work every day**.  \n",
        "- Marking **“current smoker”** and **“has never smoked regularly”** on different pages.  \n",
        "- A male participant answering **“post-menopausal”** or reporting **age at menopause**.\n",
        "\n",
        "FB2NEP does not include explicit test questions, but you can treat these kinds of\n",
        "*internal contradictions* as serving a similar purpose: they flag records that may\n",
        "need closer inspection or, in some analyses, exclusion.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rare-values-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5.2 Simple frequency tables for key categorical variables\n",
        "\n",
        "for col in [\"sex\", \"SES_class\", \"smoking_status\", \"physical_activity\"]:\n",
        "    if col in df.columns:\n",
        "        print(f\"\\nValue counts for {col}:\")\n",
        "        print(df[col].value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "missing-data-text",
      "metadata": {},
      "source": [
        "## 6. Missing data: MCAR, MAR, MNAR (overview)\n",
        "\n",
        "Almost all real datasets contain missing values. Three concepts are important:\n",
        "\n",
        "- **MCAR (Missing Completely At Random)**:\n",
        "  - The probability of missingness is unrelated to observed or unobserved data.\n",
        "  - Example: a random sample of blood tubes is lost in the post.\n",
        "- **MAR (Missing At Random)**:\n",
        "  - The probability of missingness depends only on observed variables.\n",
        "  - Example: older participants are less likely to provide a urine sample, but age is recorded.\n",
        "- **MNAR (Missing Not At Random)**:\n",
        "  - The probability of missingness depends on unobserved values.\n",
        "  - Example: participants with very high alcohol intake are less likely to report their intake.\n",
        "\n",
        "In the synthetic dataset we have:\n",
        "\n",
        "- MCAR-type missingness on some biomarker and diet variables.\n",
        "- MAR-type missingness depending on age and deprivation.\n",
        "- Small MNAR components for alcohol and BMI.\n",
        "\n",
        "We start by computing the proportion missing in each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "missing-fraction",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6.1 Proportion of missing values in each variable\n",
        "\n",
        "missing_fraction = df.isna().mean().sort_values(ascending=False)\n",
        "missing_fraction.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "missing-barplot",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6.2 Visualising missingness for the top 25 variables\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "missing_fraction.head(25).plot(kind=\"bar\")\n",
        "plt.ylabel(\"Proportion missing\")\n",
        "plt.title(\"Proportion of missing values (top 25 variables)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bmi-missing-age",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6.3 Example: does missing BMI depend on age?\n",
        "\n",
        "if {\"BMI\", \"age\"}.issubset(df.columns):\n",
        "    df[\"BMI_missing\"] = df[\"BMI\"].isna()\n",
        "    print(\"Age distribution by BMI missingness:\")\n",
        "    display(df.groupby(\"BMI_missing\")[\"age\"].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mar-imd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6.4 Example: does missing fruit_veg_g_d depend on IMD_quintile? (MAR pattern)\n",
        "\n",
        "if {\"fruit_veg_g_d\", \"IMD_quintile\"}.issubset(df.columns):\n",
        "    df[\"FV_missing\"] = df[\"fruit_veg_g_d\"].isna()\n",
        "    tab = pd.crosstab(df[\"IMD_quintile\"], df[\"FV_missing\"], normalize=\"index\")\n",
        "    print(\"Proportion missing fruit_veg_g_d by IMD_quintile:\")\n",
        "    display(tab)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "validation-text",
      "metadata": {},
      "source": [
        "## 7. Simple validation checks\n",
        "\n",
        "Finally we perform a few simple validation checks:\n",
        "\n",
        "- Are there any men with a non-\"NA\" menopausal status?\n",
        "- Do key variables have reasonable distributions by sex or SES?\n",
        "- Are any obvious coding errors visible when we group by categories?\n",
        "\n",
        "These checks will inform later modelling decisions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "validate-meno",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7.1 Check that menopausal_status is only set for women\n",
        "\n",
        "if {\"sex\", \"menopausal_status\"}.issubset(df.columns):\n",
        "    inconsistent = df[(df[\"sex\"] == \"M\") & (df[\"menopausal_status\"] != \"NA\")]\n",
        "    print(f\"Number of men with non-NA menopausal_status: {len(inconsistent)}\")\n",
        "    display(inconsistent.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "validate-bp-sex",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7.2 Check SBP distribution by sex\n",
        "\n",
        "if {\"SBP\", \"sex\"}.issubset(df.columns):\n",
        "    print(\"SBP by sex:\")\n",
        "    display(df.groupby(\"sex\")[\"SBP\"].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "summary-text",
      "metadata": {},
      "source": [
        "## 8. Summary\n",
        "\n",
        "- We distinguished between **continuous**, **categorical**, **ordinal**, and **count** variables,\n",
        "  and saw how they are stored and summarised in Python.\n",
        "- We discussed how **coding** (for example, collapsing BMI or SES) always involves\n",
        "  some **loss of information**, which must be balanced against simplicity.\n",
        "- We outlined typical **data collection pipelines** in nutritional epidemiology and\n",
        "  highlighted the importance of units and harmonisation across data sources.\n",
        "- We used simple **plausibility checks** to flag extreme values for BMI, SBP, and energy intake,\n",
        "  and introduced the idea behind the **Goldberg cut-off**.\n",
        "- We explored **rare categories**, “Prefer not to say”, and the idea of **test questions** and\n",
        "  internal consistency.\n",
        "- We introduced the concepts of **MCAR**, **MAR** and **MNAR** missingness and examined\n",
        "  missing patterns for selected variables.\n",
        "- We performed a few **validation checks** (for example, menopausal status in men) to illustrate\n",
        "  how coding errors can be detected early.\n",
        "\n",
        "These steps are part of routine data cleaning in nutritional epidemiology and prepare the ground\n",
        "for later workbooks on sampling, representativeness, and modelling."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
