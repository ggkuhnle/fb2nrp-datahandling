{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "wb8_title",
      "metadata": {},
      "source": [
        "# FB2NEP Workbook 8 – Missing Data and Sensitivity Analysis\n",
        "\n",
        "Version 0.0.1\n",
        "\n",
        "In all real epidemiological datasets, some information is missing. In this workbook we focus more systematically on:\n",
        "\n",
        "- What “missing data” mean in practice.\n",
        "- Patterns of missingness in the FB2NEP cohort.\n",
        "- Complete-case versus imputation-based analyses.\n",
        "- Simple sensitivity analyses to assess robustness.\n",
        "- A brief introduction to Bayesian thinking about missing data.\n",
        "\n",
        "We work with a simple regression example using the synthetic FB2NEP cohort.\n",
        "\n",
        "Run the first two code cells to set up the repository and load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wb8_bootstrap",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# FB2NEP bootstrap cell (works both locally and in Colab)\n",
        "#\n",
        "# What this cell does:\n",
        "# - Ensures that we are inside the fb2nep-epi repository.\n",
        "# - In Colab: clones the repository from GitHub if necessary.\n",
        "# - Loads and runs scripts/bootstrap.py.\n",
        "# - Makes the main dataset available as the variable `df`.\n",
        "#\n",
        "# Important:\n",
        "# - You may see messages printed below (for example from pip\n",
        "#   or from the bootstrap script). This is expected.\n",
        "# - You may also see WARNINGS (often in yellow). In most cases\n",
        "#   these are harmless and can be ignored for this module.\n",
        "# - The main thing to watch for is a red error traceback\n",
        "#   (for example FileNotFoundError, ModuleNotFoundError).\n",
        "#   If that happens, please re-run this cell first. If the\n",
        "#   error persists, ask for help.\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import pathlib\n",
        "import subprocess\n",
        "import importlib.util\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Configuration: repository location and URL\n",
        "# ------------------------------------------------------------\n",
        "# REPO_URL: address of the GitHub repository.\n",
        "# REPO_DIR: folder name that will be created when cloning.\n",
        "REPO_URL = \"https://github.com/ggkuhnle/fb2nep-epi.git\"\n",
        "REPO_DIR = \"fb2nep-epi\"\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1. Ensure we are inside the fb2nep-epi repository\n",
        "# ------------------------------------------------------------\n",
        "# In local Jupyter, you may already be inside the repository,\n",
        "# for example in fb2nep-epi/notebooks.\n",
        "#\n",
        "# In Colab, the default working directory is /content, so\n",
        "# we need to clone the repository into /content/fb2nep-epi\n",
        "# and then change into that folder.\n",
        "cwd = pathlib.Path.cwd()\n",
        "\n",
        "# Case A: we are already in the repository (scripts/bootstrap.py exists here)\n",
        "if (cwd / \"scripts\" / \"bootstrap.py\").is_file():\n",
        "    repo_root = cwd\n",
        "\n",
        "# Case B: we are outside the repository (for example in Colab)\n",
        "else:\n",
        "    repo_root = cwd / REPO_DIR\n",
        "\n",
        "    # Clone the repository if it is not present yet\n",
        "    if not repo_root.is_dir():\n",
        "        print(f\"Cloning repository from {REPO_URL} into {repo_root} ...\")\n",
        "        subprocess.run([\"git\", \"clone\", REPO_URL, str(repo_root)], check=True)\n",
        "    else:\n",
        "        print(f\"Using existing repository at {repo_root}\")\n",
        "\n",
        "    # Change the working directory to the repository root\n",
        "    os.chdir(repo_root)\n",
        "    repo_root = pathlib.Path.cwd()\n",
        "\n",
        "print(f\"Repository root set to: {repo_root}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2. Load scripts/bootstrap.py as a module and call init()\n",
        "# ------------------------------------------------------------\n",
        "# The shared bootstrap script contains all logic to:\n",
        "# - Ensure that required Python packages are installed.\n",
        "# - Ensure that the synthetic dataset exists (and generate it\n",
        "#   if needed).\n",
        "# - Load the dataset into a pandas DataFrame.\n",
        "#\n",
        "# We load the script as a normal Python module (fb2nep_bootstrap)\n",
        "# and then call its init() function.\n",
        "bootstrap_path = repo_root / \"scripts\" / \"bootstrap.py\"\n",
        "\n",
        "if not bootstrap_path.is_file():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Could not find {bootstrap_path}. \"\n",
        "        \"Please check that the fb2nep-epi repository structure is intact.\"\n",
        "    )\n",
        "\n",
        "# Create a module specification from the file\n",
        "spec = importlib.util.spec_from_file_location(\"fb2nep_bootstrap\", bootstrap_path)\n",
        "bootstrap = importlib.util.module_from_spec(spec)\n",
        "sys.modules[\"fb2nep_bootstrap\"] = bootstrap\n",
        "\n",
        "# Execute the bootstrap script in the context of this module\n",
        "spec.loader.exec_module(bootstrap)\n",
        "\n",
        "# The init() function is defined in scripts/bootstrap.py.\n",
        "# It returns:\n",
        "# - df   : the main synthetic cohort as a pandas DataFrame.\n",
        "# - CTX  : a small context object with paths, flags and settings.\n",
        "df, CTX = bootstrap.init()\n",
        "\n",
        "# Optionally expose a few additional useful variables from the\n",
        "# bootstrap module (if they exist). These are not essential for\n",
        "# most analyses, but can be helpful for advanced use.\n",
        "for name in [\"CSV_REL\", \"REPO_NAME\", \"REPO_URL\", \"IN_COLAB\"]:\n",
        "    if hasattr(bootstrap, name):\n",
        "        globals()[name] = getattr(bootstrap, name)\n",
        "\n",
        "print(\"Bootstrap completed successfully.\")\n",
        "print(\"The main dataset is available as the variable `df`.\")\n",
        "print(\"The context object is available as `CTX`.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wb8_imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports used throughout this workbook\n",
        "#\n",
        "# - numpy, pandas: general data handling\n",
        "# - matplotlib: simple visualisations\n",
        "# - statsmodels: regression and multiple imputation (MICE)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.imputation.mice import MICEData, MICE\n",
        "\n",
        "from scripts.helpers_tables import ensure_cmdstan\n",
        "\n",
        "cmdstan_root = ensure_cmdstan()\n",
        "\n",
        "from cmdstanpy import CmdStanModel\n",
        "print(\"Using CmdStan from:\", cmdstan_root)\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wb8_head",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick inspection of the main dataset\n",
        "# This is just to remind ourselves of the structure of the FB2NEP cohort.\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wb8_background_missing",
      "metadata": {},
      "source": [
        "## Background: what do we mean by “missing data”?\n",
        "\n",
        "Before inspecting missingness in the FB2NEP dataset, we first clarify what *missing* means in an epidemiological context.\n",
        "\n",
        "### (a) What can be missing?\n",
        "\n",
        "Information can be missing at several levels:\n",
        "\n",
        "- **Whole participants**  \n",
        "  These individuals never appear in the analysis dataset (not recruited, withdrew immediately, or provided no usable data).\n",
        "\n",
        "- **Entire visits or time points**  \n",
        "  A participant attends baseline but not follow-up; in longitudinal data this appears as absent rows or missing whole sets of variables.\n",
        "\n",
        "- **Individual variables (items)**  \n",
        "  A single measurement is absent:  \n",
        "  - SBP not taken or not recorded.  \n",
        "  - Height or weight missing.  \n",
        "  - A questionnaire item skipped.\n",
        "\n",
        "In this workbook we mainly deal with **item-level missingness** in outcome, exposure, and covariates within a regression model.\n",
        "\n",
        "### (b) Different types of missing entries\n",
        "\n",
        "Not all missing values have the same meaning:\n",
        "\n",
        "- **Item non-response**  \n",
        "  A measurement *should* exist, but is not observed.\n",
        "\n",
        "- **Unit non-response**  \n",
        "  A whole clinic visit or questionnaire is missing.\n",
        "\n",
        "- **Structurally missing (“not applicable”)**  \n",
        "  These entries are *supposed* to be missing. Examples:  \n",
        "  - `menopausal_status` in men.  \n",
        "  - `CVD_date` for participants without a CVD event.  \n",
        "\n",
        "Structural missingness is not imputed because it is determined by the logic of the variable.\n",
        "\n",
        "### (c) What does “missing” mean in the dataset?\n",
        "\n",
        "In the FB2NEP dataset, missing values appear as `NaN` in pandas.\n",
        "\n",
        "This means:\n",
        "\n",
        "- The participant **exists** in the cohort.  \n",
        "- But the dataset contains **no recorded value** for that variable.\n",
        "\n",
        "It does **not** mean:\n",
        "\n",
        "- zero,  \n",
        "- “no disease”,  \n",
        "- “never”,  \n",
        "- or any other substantive category.\n",
        "\n",
        "Example:\n",
        "\n",
        "- `SBP = 0` mmHg would be physiologically impossible and signals an error.  \n",
        "- `SBP = NaN` means the measurement was not collected or not available.\n",
        "\n",
        "Missingness therefore concerns the **measurement**, not the person. A missing BMI does not mean the participant lacks body mass; it means the dataset lacks the recorded value.\n",
        "\n",
        "In the rest of this workbook, we focus on:\n",
        "\n",
        "- How much item-level missingness there is in our chosen variables.  \n",
        "- How different ways of handling these missing values (complete-case analysis, single imputation, multiple imputation) can influence our regression results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wb8_missing_overview",
      "metadata": {},
      "source": [
        "## 1. Missingness overview\n",
        "\n",
        "We now turn to the concrete pattern of missing data in the FB2NEP cohort.\n",
        "\n",
        "In this workbook we focus on a simple blood pressure model:\n",
        "\n",
        "- Outcome: `SBP` (systolic blood pressure).\n",
        "- Main exposure: `BMI` (body mass index).\n",
        "- Covariates: `age`, `sex`, `smoking_status`, `SES_class`.\n",
        "\n",
        "We begin by calculating the proportion of missing values in each of these variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wb8_missing_props",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select variables of interest for this workbook.\n",
        "#\n",
        "# We keep the code robust by checking that each variable actually exists in df.\n",
        "\n",
        "vars_of_interest = [v for v in [\"SBP\", \"BMI\", \"age\", \"sex\", \"smoking_status\", \"SES_class\"] if v in df.columns]\n",
        "df_an = df[vars_of_interest].copy()\n",
        "\n",
        "# Ensure that categorical variables are coded as categories.\n",
        "if \"sex\" in df_an.columns:\n",
        "    df_an[\"sex\"] = df_an[\"sex\"].astype(\"category\")\n",
        "if \"smoking_status\" in df_an.columns:\n",
        "    df_an[\"smoking_status\"] = df_an[\"smoking_status\"].astype(\"category\")\n",
        "if \"SES_class\" in df_an.columns:\n",
        "    df_an[\"SES_class\"] = df_an[\"SES_class\"].astype(\"category\")\n",
        "\n",
        "# Proportion of missing values for each variable.\n",
        "missing_props = df_an.isna().mean()\n",
        "missing_props"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wb8_missing_bar_intro",
      "metadata": {},
      "source": [
        "The table above shows the **fraction** of missing values for each variable.\n",
        "\n",
        "- A value of `0.05` means that 5% of observations for that variable are missing.\n",
        "- The amount of missing data can differ markedly between variables.\n",
        "\n",
        "To visualise this pattern we can draw a simple bar chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wb8_missing_barplot",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bar plot of missingness for the selected variables.\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "missing_props.sort_values(ascending=False).plot(kind=\"bar\")\n",
        "plt.ylabel(\"Proportion missing\")\n",
        "plt.ylim(0, 1)\n",
        "plt.title(\"Proportion of missing values by variable\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wb8_mechanisms",
      "metadata": {},
      "source": [
        "### 1.1 Conceptual mechanisms of missingness\n",
        "\n",
        "The statistical properties of any missing-data method depend on **how** data are missing. Three standard mechanisms are:\n",
        "\n",
        "- **MCAR – Missing Completely At Random**  \n",
        "  The probability that a value is missing does not depend on any observed or unobserved variable. For example, a blood sample is lost due to a laboratory freezer failure that affects samples randomly.\n",
        "\n",
        "- **MAR – Missing At Random**  \n",
        "  The probability that a value is missing may depend on **observed** variables, but not on the value of the missing variable itself, after conditioning on the observed data. For example, BMI may be more likely to be missing among older participants, but conditional on age and sex, missingness is unrelated to the true BMI value.\n",
        "\n",
        "- **MNAR – Missing Not At Random**  \n",
        "  The probability that a value is missing still depends on the *unobserved* value, even after conditioning on observed covariates. For example, participants with very high BMI may be particularly reluctant to be weighed, even after adjusting for age, sex and smoking.\n",
        "\n",
        "In practice we rarely know the true mechanism. A key message is: therefore:\n",
        "\n",
        "> We can rarely “fix” missing data, but we can **make our assumptions explicit** and **explore sensitivity** of results to these assumptions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wb8_cc_vs_impute",
      "metadata": {},
      "source": [
        "## 2. Complete-case versus single imputation\n",
        "\n",
        "We now fit a simple linear regression model with systolic blood pressure (SBP) as the outcome and BMI as the main exposure, adjusted for age and available covariates.\n",
        "\n",
        "We compare two strategies:\n",
        "\n",
        "1. **Complete-case analysis**: use only participants with no missing values in any of the model variables. This is easy but can lead to loss of power and biased estimates, unless data are MCAR (or satisfy a slightly weaker condition).\n",
        "2. **Single imputation**: fill in missing values with a single “best guess” (mean or mode) and analyse the resulting dataset as if it were complete. This preserves sample size but underestimates uncertainty.\n",
        "\n",
        "We start with the complete-case analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wb8_cc_model",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.1 Complete-case analysis\n",
        "# --------------------------\n",
        "# We drop any row that has at least one missing value in the variables\n",
        "# we intend to use in the model.\n",
        "\n",
        "df_cc = df_an.dropna()\n",
        "print(f\"Number of complete cases: {len(df_cc)} out of {len(df_an)} participants\")\n",
        "\n",
        "# Construct the regression formula step by step.\n",
        "formula = \"SBP ~ BMI + age\"\n",
        "if \"sex\" in df_cc.columns:\n",
        "    formula += \" + C(sex)\"\n",
        "if \"smoking_status\" in df_cc.columns:\n",
        "    formula += \" + C(smoking_status)\"\n",
        "if \"SES_class\" in df_cc.columns:\n",
        "    formula += \" + C(SES_class)\"\n",
        "\n",
        "print(\"Model formula:\", formula)\n",
        "\n",
        "# Fit the ordinary least squares (OLS) model using statsmodels.\n",
        "model_cc = smf.ols(formula, data=df_cc).fit()\n",
        "\n",
        "# Create a compact summary table with estimates and 95% confidence intervals.\n",
        "cc_summary = model_cc.summary2().tables[1][[\"Coef.\", \"Std.Err.\", \"[0.025\", \"0.975]\"]]\n",
        "cc_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wb8_single_impute",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2.2 Single imputation (mean/mode)\n",
        "# ---------------------------------\n",
        "# For illustration, we perform a very simple single imputation:\n",
        "# - For numeric variables, replace missing values with the mean.\n",
        "# - For categorical variables, replace missing values with the most frequent category.\n",
        "#\n",
        "# This method is *not* recommended for serious analyses, but it is useful to\n",
        "# demonstrate how different handling of missing data can influence estimates.\n",
        "\n",
        "df_si = df_an.copy()\n",
        "\n",
        "for col in df_si.columns:\n",
        "    if df_si[col].dtype.kind in \"biufc\":  # numeric types\n",
        "        df_si[col] = df_si[col].fillna(df_si[col].mean())\n",
        "    else:  # categorical or object types\n",
        "        df_si[col] = df_si[col].fillna(df_si[col].mode().iloc[0])\n",
        "\n",
        "# Fit the same model to the single-imputed dataset.\n",
        "model_si = smf.ols(formula, data=df_si).fit()\n",
        "\n",
        "si_summary = model_si.summary2().tables[1][[\"Coef.\", \"Std.Err.\", \"[0.025\", \"0.975]\"]]\n",
        "\n",
        "# Compare coefficients from complete-case and single-imputed analyses.\n",
        "comparison_2 = pd.DataFrame({\n",
        "    \"cc_coef\": cc_summary[\"Coef.\"],\n",
        "    \"si_coef\": si_summary[\"Coef.\"],\n",
        "    \"cc_SE\": cc_summary[\"Std.Err.\"],\n",
        "    \"si_SE\": si_summary[\"Std.Err.\"]\n",
        "})\n",
        "comparison_2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wb8_cc_si_interpret",
      "metadata": {},
      "source": [
        "In the table above, focus on the **BMI** coefficient and its standard error in the two approaches.\n",
        "\n",
        "- Do the point estimates differ?  \n",
        "- Are the confidence intervals similar or noticeably different?  \n",
        "- How many observations were used in the complete-case analysis compared with the imputed analysis?\n",
        "\n",
        "Single imputation keeps the original sample size but fails to reflect the extra uncertainty caused by missing data, so standard errors are often too small."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wb8_mi_intro",
      "metadata": {},
      "source": [
        "## 3. Multiple imputation with MICE (simplified)\n",
        "\n",
        "Multiple imputation aims to improve on single imputation by:\n",
        "\n",
        "1. Drawing **several** plausible values for each missing observation, generating multiple imputed datasets.\n",
        "2. Fitting the analysis model in each dataset.\n",
        "3. Combining estimates and standard errors using **Rubin's rules**.\n",
        "\n",
        "Conceptually, this is closer to the idea of uncertainty used elsewhere in statistics: we acknowledge that the missing values could have been different, and we propagate this uncertainty into the final estimates.\n",
        "\n",
        "Here we use a simple implementation of **MICE (Multivariate Imputation by Chained Equations)** from `statsmodels`. The details of the imputation models are beyond the scope of FB2NEP; we treat this as a black box and focus on the *idea* and the comparison of results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wb8_mice_prep",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.1 Prepare data for MICE\n",
        "# -------------------------\n",
        "# MICE in statsmodels expects a numeric design matrix. We therefore use\n",
        "# one-hot encoding (dummy variables) for categories.\n",
        "\n",
        "df_mice = pd.get_dummies(df_an, drop_first=True)\n",
        "\n",
        "# Create a MICEData object that stores the data and handles the chained equations.\n",
        "mice_data = MICEData(df_mice)\n",
        "\n",
        "# Outcome and predictors: here we use all available predictors for imputation\n",
        "# and analysis (this is not always ideal, but sufficient for illustration).\n",
        "endog = \"SBP\"\n",
        "predictors = [c for c in df_mice.columns if c != endog]\n",
        "formula_mice = endog + \" ~ \" + \" + \".join(predictors)\n",
        "print(\"MICE model formula:\")\n",
        "print(formula_mice)\n",
        "\n",
        "# 3.2 Fit the MICE model with m=5 imputations.\n",
        "# --------------------------------------------\n",
        "# The MICE object performs imputations internally and then fits the regression\n",
        "# model repeatedly, combining estimates automatically.\n",
        "\n",
        "# Note: first argument = formula, second = *class* with .from_formula (sm.OLS)\n",
        "mice = MICE(formula_mice, sm.OLS, mice_data)\n",
        "result_mice = mice.fit(5)\n",
        "\n",
        "# The summary is long, but it shows pooled estimates and standard errors.\n",
        "result_mice.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wb8_mice_compare",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.3 Extract and compare key coefficients across methods\n",
        "# -------------------------------------------------------\n",
        "# We focus on the BMI effect. For the MICE model, BMI is numeric and should\n",
        "# appear among the exogenous (predictor) names.\n",
        "\n",
        "# 1. Get BMI coefficient and SE from the complete-case and single-impute models\n",
        "bmi_cc_coef = model_cc.params.get(\"BMI\", np.nan)\n",
        "bmi_cc_se   = model_cc.bse.get(\"BMI\", np.nan)\n",
        "\n",
        "bmi_si_coef = model_si.params.get(\"BMI\", np.nan)\n",
        "bmi_si_se   = model_si.bse.get(\"BMI\", np.nan)\n",
        "\n",
        "print(\"Raw BMI coefficients from the two frequentist models:\")\n",
        "print(f\"  Complete-case BMI coef: {bmi_cc_coef:.6f}\")\n",
        "print(f\"  Single-impute BMI coef: {bmi_si_coef:.6f}\")\n",
        "\n",
        "# 2. Wrap the pooled MICE parameters and standard errors in a DataFrame\n",
        "pooled = pd.DataFrame(\n",
        "    {\n",
        "        \"coef\": result_mice.params,\n",
        "        \"se\": result_mice.bse,\n",
        "    },\n",
        "    index=result_mice.model.exog_names,\n",
        ")\n",
        "\n",
        "if \"BMI\" in pooled.index:\n",
        "    bmi_mi_coef = pooled.loc[\"BMI\", \"coef\"]\n",
        "    bmi_mi_se   = pooled.loc[\"BMI\", \"se\"]\n",
        "else:\n",
        "    bmi_mi_coef = np.nan\n",
        "    bmi_mi_se   = np.nan\n",
        "\n",
        "print(f\"  Multiple-impute BMI coef: {bmi_mi_coef:.6f}\")\n",
        "\n",
        "# 3. Assemble comparison table\n",
        "summary_methods = pd.DataFrame({\n",
        "    \"method\":   [\"complete_case\", \"single_impute\", \"multiple_impute\"],\n",
        "    \"BMI_coef\": [bmi_cc_coef,     bmi_si_coef,     bmi_mi_coef],\n",
        "    \"BMI_SE\":   [bmi_cc_se,       bmi_si_se,       bmi_mi_se],\n",
        "    \"n_used\":   [len(df_cc),      len(df_si),      len(df_an)],\n",
        "})\n",
        "\n",
        "summary_methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wb8_mi_interpret",
      "metadata": {},
      "source": [
        "This table summarises the estimated BMI effect and its standard error under three strategies.\n",
        "\n",
        "- Multiple imputation typically has **smaller standard errors** than complete-case analysis (because it uses more data) but **larger standard errors** than naive single imputation (because it acknowledges imputation uncertainty).\n",
        "- In well-behaved situations, point estimates are often similar across methods, but they **can** differ, especially if missingness is related to key variables.\n",
        "\n",
        "Even a moderately sceptical hippo would insist that the assumptions behind each method are made clear in any report or dissertation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wb8_sensitivity_intro",
      "metadata": {},
      "source": [
        "## 4. Simple sensitivity analyses\n",
        "\n",
        "No missing-data method is perfect, and the mechanism of missingness is usually not known with certainty. **Sensitivity analyses** explore how robust our conclusions are to alternative assumptions or modelling choices.\n",
        "\n",
        "Here we illustrate two simple strategies:\n",
        "\n",
        "1. Restricting the analysis to a more “ordinary” BMI range.\n",
        "2. Applying a small **delta adjustment** to imputed values to mimic an MNAR scenario."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wb8_sens_restrict",
      "metadata": {},
      "source": [
        "### 4.1 Restricting the BMI range\n",
        "\n",
        "Extreme values can sometimes drive results and may also be more prone to measurement error or missingness. As a basic sensitivity analysis, we refit the complete-case model **excluding** participants with BMI ≥ 40 kg/m² and compare results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wb8_sens_restrict_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.1 Restrict analysis to BMI < 40 kg/m^2\n",
        "\n",
        "if \"BMI\" in df_cc.columns:\n",
        "    df_cc_restricted = df_cc[df_cc[\"BMI\"] < 40]\n",
        "    print(f\"Complete cases in original model:   {len(df_cc)}\")\n",
        "    print(f\"Complete cases with BMI < 40:      {len(df_cc_restricted)}\")\n",
        "\n",
        "    model_cc_rest = smf.ols(formula, data=df_cc_restricted).fit()\n",
        "\n",
        "    cc_rest_summary = model_cc_rest.summary2().tables[1][[\"Coef.\", \"Std.Err.\", \"[0.025\", \"0.975]\"]]\n",
        "\n",
        "    comp_rest = pd.DataFrame({\n",
        "        \"original_coef\": cc_summary[\"Coef.\"],\n",
        "        \"restricted_coef\": cc_rest_summary[\"Coef.\"],\n",
        "        \"original_SE\": cc_summary[\"Std.Err.\"],\n",
        "        \"restricted_SE\": cc_rest_summary[\"Std.Err.\"],\n",
        "    })\n",
        "    comp_rest"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "979a2172",
      "metadata": {},
      "source": [
        "### 4.3 Sensitivity to adjustment set (model specification)\n",
        "\n",
        "Sensitivity analyses are not limited to missing data. In epidemiology, it is good practice\n",
        "to ask how sensitive our main association is to *modelling choices*, in particular:\n",
        "\n",
        "- Which covariates we adjust for (potential confounders).\n",
        "- How we code exposures and covariates (continuous vs categories).\n",
        "- Functional form (for example, linear vs quadratic).\n",
        "\n",
        "Here we consider the association between BMI and SBP and compare two regression models:\n",
        "\n",
        "1. A **minimally adjusted model**:  \n",
        "   $$\n",
        "   \\text{SBP} = \\beta_0 + \\beta_1 \\cdot \\text{BMI} + \\beta_2 \\cdot \\text{age} + \\beta_3 \\cdot \\text{sex} + \\varepsilon.\n",
        "   $$\n",
        "\n",
        "2. A **more fully adjusted model** that also includes potential confounders:  \n",
        "   $$\n",
        "   \\text{SBP} = \\beta_0 + \\beta_1 \\cdot \\text{BMI} + \\beta_2 \\cdot \\text{age}\n",
        "   + \\beta_3 \\cdot \\text{sex} + \\beta_4 \\cdot \\text{smoking status}\n",
        "   + \\beta_5 \\cdot \\text{SES} + \\beta_6 \\cdot \\text{physical activity} + \\varepsilon.\n",
        "   $$\n",
        "\n",
        "The aim is to see whether the estimated BMI effect (\\\\(\\\\beta_1\\\\)) is stable or changes\n",
        "substantially when we change the adjustment set. Large changes might indicate strong\n",
        "confounding or model misspecification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9a1378a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.3 Sensitivity to adjustment set (model specification)\n",
        "# ------------------------------------------------------\n",
        "# We use the complete-case dataset df_cc and compare:\n",
        "# - A minimally adjusted model: SBP ~ BMI + age + sex\n",
        "# - A more fully adjusted model: add smoking_status, SES_class, physical_activity (if present)\n",
        "\n",
        "# Ensure we are working with complete cases for all relevant variables.\n",
        "covars_min = [\"age\", \"sex\"]\n",
        "covars_full = [\"age\", \"sex\", \"smoking_status\", \"SES_class\", \"physical_activity\"]\n",
        "\n",
        "# Keep only variables that actually exist in the data.\n",
        "covars_min = [v for v in covars_min if v in df_cc.columns]\n",
        "covars_full = [v for v in covars_full if v in df_cc.columns]\n",
        "\n",
        "vars_min = [\"SBP\", \"BMI\"] + covars_min\n",
        "vars_full = [\"SBP\", \"BMI\"] + covars_full\n",
        "\n",
        "df_cc_min = df_cc[vars_min].dropna()\n",
        "df_cc_full = df_cc[vars_full].dropna()\n",
        "\n",
        "print(f\"Minimally adjusted model:   {len(df_cc_min)} complete cases\")\n",
        "print(f\"Fully adjusted model:       {len(df_cc_full)} complete cases\")\n",
        "\n",
        "# Construct formulas\n",
        "formula_min = \"SBP ~ BMI\"\n",
        "for cov in covars_min:\n",
        "    if str(df_cc_min[cov].dtype) == \"category\":\n",
        "        formula_min += f\" + C({cov})\"\n",
        "    else:\n",
        "        formula_min += f\" + {cov}\"\n",
        "\n",
        "formula_full = \"SBP ~ BMI\"\n",
        "for cov in covars_full:\n",
        "    if str(df_cc_full[cov].dtype) == \"category\":\n",
        "        formula_full += f\" + C({cov})\"\n",
        "    else:\n",
        "        formula_full += f\" + {cov}\"\n",
        "\n",
        "print(\"Minimal model formula:   \", formula_min)\n",
        "print(\"Full model formula:      \", formula_full)\n",
        "\n",
        "# Fit both models\n",
        "model_min = smf.ols(formula_min, data=df_cc_min).fit()\n",
        "model_full = smf.ols(formula_full, data=df_cc_full).fit()\n",
        "\n",
        "# Extract BMI coefficients and standard errors\n",
        "bmi_min_coef = model_min.params.get(\"BMI\", np.nan)\n",
        "bmi_min_se   = model_min.bse.get(\"BMI\", np.nan)\n",
        "\n",
        "bmi_full_coef = model_full.params.get(\"BMI\", np.nan)\n",
        "bmi_full_se   = model_full.bse.get(\"BMI\", np.nan)\n",
        "\n",
        "sens_adjust = pd.DataFrame({\n",
        "    \"model\": [\"minimal\", \"full\"],\n",
        "    \"BMI_coef\": [bmi_min_coef, bmi_full_coef],\n",
        "    \"BMI_SE\": [bmi_min_se, bmi_full_se],\n",
        "    \"n_used\": [len(df_cc_min), len(df_cc_full)],\n",
        "})\n",
        "\n",
        "sens_adjust\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wb8_bayes",
      "metadata": {},
      "source": [
        "## 5. Bayesian approaches\n",
        "\n",
        "Bayesian methods treat missing values as **unknown parameters** and estimate them jointly with all other parameters in the model.\n",
        "\n",
        "In a Bayesian missing-data model:\n",
        "\n",
        "- We specify a **likelihood** for the observed data given parameters and missing values.\n",
        "- We specify **prior distributions** for both the model parameters and the missing values.\n",
        "- We use Markov Chain Monte Carlo (MCMC) or related algorithms to sample from the joint **posterior distribution**.\n",
        "\n",
        "The resulting posterior samples naturally incorporate uncertainty about missing values into uncertainty about regression coefficients. This is conceptually similar to multiple imputation, but the Bayesian approach integrates all uncertainty in a single framework and can make it easier to specify complex MNAR models.\n",
        "\n",
        "Implementing Bayesian missing-data models is beyond the scope of FB2NEP, but it is useful to be aware of them, particularly for more advanced research projects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48c99c67",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Bayesian regression with Stan (CmdStanPy)\n",
        "# --------------------------------------------\n",
        "# Model: SBP ~ BMI + age + sex\n",
        "#\n",
        "# We use weakly informative priors and sample from the posterior using Stan,\n",
        "# accessed via CmdStanPy. This is an illustrative example that mirrors the\n",
        "# frequentist linear regression used earlier.\n",
        "\n",
        "\n",
        "# If you have put these helpers into a module, import them here, e.g.:\n",
        "# from helpers_bayes import ensure_cmdstan, stan_summary_table\n",
        "# For a standalone notebook, you can paste the helper definitions above this cell.\n",
        "\n",
        "cmdstan_root = ensure_cmdstan()\n",
        "\n",
        "from cmdstanpy import CmdStanModel\n",
        "print(\"Using CmdStan from:\", cmdstan_root)\n",
        "\n",
        "# Prepare a clean analysis dataset (complete cases for the relevant variables)\n",
        "\n",
        "df_bayes = df_an.dropna(subset=[\"SBP\", \"BMI\", \"age\", \"sex\"]).copy()\n",
        "df_bayes[\"sex_M\"] = (df_bayes[\"sex\"] == \"M\").astype(float)  # float now\n",
        "\n",
        "data_stan = {\n",
        "    \"N\": len(df_bayes),\n",
        "    \"SBP\": df_bayes[\"SBP\"].to_numpy(),\n",
        "    \"BMI\": df_bayes[\"BMI\"].to_numpy(),\n",
        "    \"age\": df_bayes[\"age\"].to_numpy(),\n",
        "    \"sex_M\": df_bayes[\"sex_M\"].to_numpy(),\n",
        "}\n",
        "\n",
        "\n",
        "print(f\"N for Bayesian model: {data_stan['N']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42ac47ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "stan_code = \"\"\"\n",
        "data {\n",
        "  int<lower=1> N;\n",
        "  vector[N] SBP;\n",
        "  vector[N] BMI;\n",
        "  vector[N] age;\n",
        "  vector[N] sex_M;        // now a vector, not a scalar\n",
        "}\n",
        "\n",
        "parameters {\n",
        "  real intercept;\n",
        "  real beta_BMI;\n",
        "  real beta_age;\n",
        "  real beta_sex;\n",
        "  real<lower=0> sigma;\n",
        "}\n",
        "\n",
        "model {\n",
        "  // Weakly informative priors\n",
        "  intercept ~ normal(120, 20);\n",
        "  beta_BMI  ~ normal(0.5, 0.5);\n",
        "  beta_age  ~ normal(0.6, 0.3);\n",
        "  beta_sex  ~ normal(0, 2);\n",
        "  sigma     ~ normal(15, 5);\n",
        "\n",
        "  // Linear predictor\n",
        "  SBP ~ normal(\n",
        "    intercept\n",
        "    + beta_BMI * BMI\n",
        "    + beta_age * age\n",
        "    + beta_sex * sex_M,\n",
        "    sigma\n",
        "  );\n",
        "}\n",
        "\"\"\"\n",
        "with open(\"sbp_regression.stan\", \"w\") as f:\n",
        "    f.write(stan_code)\n",
        "\n",
        "sbp_model = CmdStanModel(stan_file=\"sbp_regression.stan\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9729319",
      "metadata": {},
      "outputs": [],
      "source": [
        "fit = sbp_model.sample(\n",
        "    data=data_stan,\n",
        "    seed=11088,\n",
        "    chains=4,\n",
        "    parallel_chains=4,\n",
        "    iter_warmup=1000,\n",
        "    iter_sampling=2000,\n",
        "    show_console=True,   # keep on while debugging\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a7aa7b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from scripts.helpers_tables import stan_summary_table\n",
        "\n",
        "param_order = [\"intercept\", \"beta_BMI\", \"beta_age\", \"beta_sex\", \"sigma\"]\n",
        "bayes_tbl = stan_summary_table(fit, param_order=param_order)\n",
        "bayes_tbl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d62aef81",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Comparison of Bayesian (Stan) and Frequentist Estimates\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "# Extract BMI, age, sex coefficients from frequentist models\n",
        "bmi_cc  = model_cc.params.get(\"BMI\", np.nan)\n",
        "age_cc  = model_cc.params.get(\"age\", np.nan)\n",
        "sex_cc  = model_cc.params.get(\"C(sex)[T.M]\", np.nan)\n",
        "\n",
        "# From MI results (already computed earlier)\n",
        "bmi_mi  = bmi_mi_coef\n",
        "age_mi  = np.nan   # replace if you computed MI for age\n",
        "sex_mi  = np.nan   # replace if you computed MI for sex\n",
        "\n",
        "# From Stan posterior means\n",
        "bmi_stan = bayes_tbl.loc[\"beta_BMI\", \"mean\"]\n",
        "age_stan = bayes_tbl.loc[\"beta_age\", \"mean\"]\n",
        "sex_stan = bayes_tbl.loc[\"beta_sex\", \"mean\"]\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    \"method\": [\"OLS (complete-case)\", \"Multiple Imputation\", \"Bayesian (Stan)\"],\n",
        "    \"BMI_coef\": [bmi_cc, bmi_mi, bmi_stan],\n",
        "})\n",
        "\n",
        "comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wb8_practical",
      "metadata": {},
      "source": [
        "## 6. Practical mini-assignment\n",
        "\n",
        "In this final section you will carry out a small, assignment-style analysis using the FB2NEP cohort.\n",
        "\n",
        "### Task\n",
        "\n",
        "1. Choose an **outcome** (for example, `SBP` or a biomarker).\n",
        "2. Choose a main **exposure** (for example, `BMI`, `salt_g_d`, or `physical_activity`).\n",
        "3. Choose at least **two covariates** (for example, `age`, `sex`, `SES_class`).\n",
        "4. Inspect and describe the pattern of missingness in your chosen variables.\n",
        "5. Fit three models:\n",
        "   - Complete-case analysis.\n",
        "   - Single imputation (mean/mode or another reasonable rule).\n",
        "   - Multiple imputation using MICE.\n",
        "6. Perform **one sensitivity analysis**, for example:\n",
        "   - Restrict the analysis to a more typical range of the exposure.\n",
        "   - Apply a small delta-based MNAR adjustment similar to Section 4.2.\n",
        "7. Write a short interpretation (approximately 150–200 words) answering:\n",
        "   - How do the point estimates differ between methods?  \n",
        "   - How do the standard errors differ?  \n",
        "   - How sensitive are your conclusions to the chosen assumptions?\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
