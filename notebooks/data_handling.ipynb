{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "intro_data_handling",
      "source": [
        "# Data Handling and Basic Analysis (Part 2 Nutrition)\n",
        "*Version 0.1.0*\n",
        "\n",
        "This workbook introduces the foundations of **data handling and basic analysis**, using a small **synthetic RCT dataset** that mimics the Part 2 practicals:\n",
        "\n",
        "- Blood pressure change after different amounts of coffee  \n",
        "- Blood glucose after different cereals  \n",
        "- Appetite VAS after different test foods  \n",
        "\n",
        "The data are **simulated** (not real student data) and include **age** and **sex**.  \n",
        "The dataset is made available as a pandas DataFrame called `df` by the **bootstrap cell above**.\n",
        "\n",
        "By the end of the workbook you should be able to:\n",
        "\n",
        "- Distinguish between **categorical**, **ordinal**, and **continuous** variables  \n",
        "- Explore a dataset with `df.info()` and `df.describe()`  \n",
        "- Compute and report **mean**, **SD**, **median**, **IQR** for continuous data  \n",
        "- Explore **distributions** and use Q–Q plots to assess normality  \n",
        "- Create **contingency tables** for categorical data  \n",
        "- Describe data appropriately for publication  \n",
        "- Understand the basics of **NHST** (H0 vs H1), **p-values**, and **95% CIs**  \n",
        "- See why p = 0.05 is not a magical threshold (we will use **α = 0.0314**)  \n",
        "- Compare two and more groups using **parametric** and **non-parametric** tests  \n",
        "- Remember that **statistics are tools, not an oracle**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "setup_imports",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Setup: scientific Python libraries and plotting style\n",
        "#\n",
        "# Assumes the bootstrap cell above has already created:\n",
        "#   - df  : the synthetic dataset (pandas DataFrame)\n",
        "#   - CTX : context object with paths and settings\n",
        "# ============================================================\n",
        "\n",
        "# Data handling and numerical computing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Statistical tests\n",
        "import scipy.stats as st\n",
        "\n",
        "# Display options (optional but helpful)\n",
        "pd.set_option(\"display.max_rows\", 20)\n",
        "pd.set_option(\"display.max_columns\", 20)\n",
        "\n",
        "# Plot style\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
        "\n",
        "print(\"Libraries loaded. DataFrame `df` is ready for analysis.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "variables_types_text",
      "source": [
        "## 1. Study variables and data types\n",
        "\n",
        "Before running any analysis, we should understand **what kind of variables** we have.\n",
        "\n",
        "Common types:\n",
        "\n",
        "- **Categorical (nominal)**: labels with no natural order (e.g. sex, treatment arm).  \n",
        "- **Ordinal**: categories with a natural order, but unknown distance between levels (e.g. Likert scales).  \n",
        "- **Continuous (or approximately continuous)**: numeric values where differences and averages make sense (e.g. age, blood pressure, VAS scores).\n",
        "\n",
        "Our synthetic dataset `df` contains (one row per participant):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "variables_table",
      "execution_count": null,
      "outputs": [],
      "source": [
        "variables = pd.DataFrame(\n",
        "    [\n",
        "        {\"variable\": \"sex\",          \"type\": \"categorical\", \"description\": \"Participant sex (F/M)\"},\n",
        "        {\"variable\": \"age\",          \"type\": \"continuous\",  \"description\": \"Age (years)\"},\n",
        "        {\"variable\": \"coffee_arm\",   \"type\": \"categorical\", \"description\": \"Coffee intervention: low / medium / high\"},\n",
        "        {\"variable\": \"cereal_arm\",   \"type\": \"categorical\", \"description\": \"Cereal: bran / cornflakes / muesli\"},\n",
        "        {\"variable\": \"food_arm\",     \"type\": \"categorical\", \"description\": \"Test food: apple / biscuit / yoghurt\"},\n",
        "        {\"variable\": \"bp_change\",    \"type\": \"continuous\",  \"description\": \"Change in blood pressure (mmHg)\"},\n",
        "        {\"variable\": \"glucose\",      \"type\": \"continuous\",  \"description\": \"Postprandial blood glucose (arbitrary units)\"},\n",
        "        {\"variable\": \"appetite_vas\", \"type\": \"continuous\",  \"description\": \"Appetite VAS (0–100)\"}\n",
        "    ]\n",
        ")\n",
        "variables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "first_look_text",
      "source": [
        "## 2. First look at the dataset\n",
        "\n",
        "We start with a **quick overview**:\n",
        "\n",
        "- `df.head()` shows the first few rows.  \n",
        "- `df.info()` summarises the variables and data types.  \n",
        "- `df.describe()` provides basic summary statistics for numeric variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "head_info",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# First few rows\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "info_cell",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Overall structure of the DataFrame\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "describe_cell",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Summary statistics for numeric variables\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "missing_values_text",
      "source": [
        "### 2.1 Missing values and impossible values\n",
        "\n",
        "We should also check for **missing values** and obviously impossible values (e.g. negative age, VAS > 100).  \n",
        "\n",
        "Our simulator does not generate missing or impossible values, but in real data these checks are essential.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "missing_values_code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Count of missing values per variable\n",
        "df.isna().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "descriptive_cont_text",
      "source": [
        "## 3. Descriptive statistics for continuous variables\n",
        "\n",
        "For continuous variables, we often report:\n",
        "\n",
        "- **Mean and standard deviation (SD)** if the distribution is roughly symmetric.  \n",
        "- **Median and interquartile range (IQR)** if the distribution is skewed.\n",
        "\n",
        "Here we compute both for the three main continuous outcomes:\n",
        "\n",
        "- `bp_change`  \n",
        "- `glucose`  \n",
        "- `appetite_vas`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "descriptive_cont_code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "cont_vars = [\"bp_change\", \"glucose\", \"appetite_vas\"]\n",
        "rows = []\n",
        "\n",
        "for var in cont_vars:\n",
        "    series = df[var].dropna()\n",
        "    mean = series.mean()\n",
        "    sd = series.std()\n",
        "    median = series.median()\n",
        "    q1 = series.quantile(0.25)\n",
        "    q3 = series.quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    rows.append({\n",
        "        \"variable\": var,\n",
        "        \"mean\": mean,\n",
        "        \"sd\": sd,\n",
        "        \"median\": median,\n",
        "        \"q1\": q1,\n",
        "        \"q3\": q3,\n",
        "        \"iqr\": iqr\n",
        "    })\n",
        "\n",
        "summary_cont = pd.DataFrame(rows)\n",
        "summary_cont\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "distributions_text",
      "source": [
        "## 4. Exploring distributions\n",
        "\n",
        "Choice of statistical test depends strongly on the **shape of the distribution**.\n",
        "\n",
        "For each continuous outcome we can:\n",
        "\n",
        "- Plot **histograms** and **density curves** (to see skew, multimodality, etc.).  \n",
        "- Use a **Q–Q plot** to compare the data to a perfect normal distribution.  \n",
        "- Compare distributions across arms using **boxplots**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "hist_bp_change",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Histogram and density for blood pressure change\n",
        "sns.histplot(df[\"bp_change\"], kde=True)\n",
        "plt.title(\"Distribution of BP change\")\n",
        "plt.xlabel(\"BP change (mmHg)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "qqplot_explanation",
      "source": [
        "### 4.1 What is a Q–Q plot?\n",
        "\n",
        "A **Quantile–Quantile (Q–Q) plot** is a way to check whether a variable follows a **normal distribution**.\n",
        "\n",
        "The idea is:\n",
        "\n",
        "- Every dataset has its own **quantiles** (for example the 10th, 50th, 90th percentile).  \n",
        "- A normal distribution also has well-defined quantiles.  \n",
        "- A Q–Q plot compares the quantiles of your data with the quantiles of a perfect normal distribution.\n",
        "\n",
        "If the data are approximately normal, the points in the Q–Q plot:\n",
        "\n",
        "- fall roughly on a straight line, especially in the middle of the distribution.\n",
        "\n",
        "Deviations can indicate:\n",
        "\n",
        "- **S-shape** → skewed distribution  \n",
        "- **Heavy tails** → more extreme values than expected  \n",
        "- **Outliers** → isolated points far from the main pattern\n",
        "\n",
        "Q–Q plots are often more informative than histograms, especially in smaller samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "qqplot_bp_change",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Q–Q plot to assess normality of BP change\n",
        "st.probplot(df[\"bp_change\"], dist=\"norm\", plot=plt)\n",
        "plt.title(\"Q–Q plot of BP change\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "boxplot_bp_coffee",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Boxplot of BP change by coffee arm\n",
        "sns.boxplot(data=df, x=\"coffee_arm\", y=\"bp_change\")\n",
        "plt.title(\"BP change by coffee intervention arm\")\n",
        "plt.xlabel(\"Coffee arm\")\n",
        "plt.ylabel(\"BP change (mmHg)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "categorical_descriptive_text",
      "source": [
        "## 5. Descriptive statistics for categorical variables\n",
        "\n",
        "For categorical variables, we usually report **counts and percentages**.\n",
        "\n",
        "Examples:\n",
        "\n",
        "- How many participants are in each **coffee_arm**?  \n",
        "- What is the distribution of **sex**?  \n",
        "- How many participants are in each **combination** (e.g. coffee arm × sex)?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "categorical_value_counts",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Distribution of participants by coffee arm\n",
        "df[\"coffee_arm\"].value_counts().to_frame(name=\"count\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "categorical_crosstab",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Contingency table: sex by coffee arm\n",
        "pd.crosstab(df[\"sex\"], df[\"coffee_arm\"], margins=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "publication_description_text",
      "source": [
        "### 5.1 Describing data properly for publication\n",
        "\n",
        "In a methods or results section, we might write:\n",
        "\n",
        "- **Continuous, roughly normal** (e.g. BP change):  \n",
        "  *\"BP change was 1.8 ± 5.2 mmHg (mean ± SD).\"*  \n",
        "- **Continuous, skewed** (e.g. VAS):  \n",
        "  *\"Appetite VAS was 62 (48–75) units (median, IQR).\"*  \n",
        "- **Categorical**:  \n",
        "  *\"40% of participants were male (n = 72/180).\"*\n",
        "\n",
        "The choice between mean ± SD and median (IQR) should be guided by **distributional shape**, not habit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "nhst_intro_text",
      "source": [
        "## 6. Statistical inference and NHST\n",
        "\n",
        "So far we have described the **sample**. Statistical inference is about what we can reasonably say about the **underlying population**.\n",
        "\n",
        "In classical **null hypothesis significance testing (NHST)** we:\n",
        "\n",
        "1. Formulate a **null hypothesis (H0)**, usually \"no difference\" or \"no effect\".  \n",
        "2. Formulate an **alternative hypothesis (H1)**, e.g. \"there is a difference\".  \n",
        "3. Choose a test statistic (e.g. a *t*-statistic) and compute it from the data.  \n",
        "4. Compute a **p-value**: the probability (under H0) of observing a result *at least as extreme* as the one we saw.  \n",
        "5. Decide whether the result is \"compatible\" with H0, often using a threshold α.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "pvalue_ci_text",
      "source": [
        "### 6.1 p-values and 95% confidence intervals\n",
        "\n",
        "- A **p-value** is *not* the probability that H0 is true. It is the probability of the observed data (or more extreme) *if H0 were true*.\n",
        "- A **95% confidence interval (CI)** for a parameter (e.g. difference in means) is an interval constructed such that, in repeated samples, 95% of such intervals would contain the true parameter.\n",
        "\n",
        "In practice:\n",
        "\n",
        "- If a 95% CI for a difference **excludes 0**, the corresponding two-sided test at α = 0.05 is \"statistically significant\".  \n",
        "- The CI also gives a sense of **precision** and **effect size**, not just a yes/no decision.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "example_ci_code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Example: difference in mean BP change between low and high coffee arms\n",
        "bp_low = df[df[\"coffee_arm\"] == \"low\"][\"bp_change\"].dropna()\n",
        "bp_high = df[df[\"coffee_arm\"] == \"high\"][\"bp_change\"].dropna()\n",
        "\n",
        "mean_low = bp_low.mean()\n",
        "mean_high = bp_high.mean()\n",
        "diff = mean_high - mean_low\n",
        "\n",
        "# Standard error for difference in means (Welch t-test style)\n",
        "se_diff = np.sqrt(bp_low.var(ddof=1)/len(bp_low) + bp_high.var(ddof=1)/len(bp_high))\n",
        "\n",
        "# 95% CI using normal approximation (for teaching; in practice use statsmodels)\n",
        "z = 1.96\n",
        "ci_lower = diff - z * se_diff\n",
        "ci_upper = diff + z * se_diff\n",
        "\n",
        "print(f\"Mean BP change (low coffee):  {mean_low:6.2f} mmHg\")\n",
        "print(f\"Mean BP change (high coffee): {mean_high:6.2f} mmHg\")\n",
        "print(f\"Difference (high - low):      {diff:6.2f} mmHg\")\n",
        "print(f\"Approx. 95% CI: [{ci_lower:6.2f}, {ci_upper:6.2f}] mmHg\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "alpha_text",
      "source": [
        "## 7. Why p = 0.05 is not a magical threshold\n",
        "\n",
        "In many papers, p < 0.05 is treated as \"significant\" and p ≥ 0.05 as \"not significant\", as if there were a sharp cliff.\n",
        "\n",
        "In reality:\n",
        "\n",
        "- 0.05 is a **convention**, not a law of nature.  \n",
        "- A p-value of 0.049 is not fundamentally different from 0.051.  \n",
        "- Decisions should also consider **effect size**, **uncertainty**, and **context**.\n",
        "\n",
        "In this workbook we deliberately use an unusual threshold **α = 0.0314** to emphasise that the choice of α is arbitrary and should be justified, not blindly copied.\n",
        "\n",
        "To see this more clearly, we simulate many RCTs with **no true difference** and look at the distribution of p-values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "pvalue_sim_code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Simulate 10 000 null experiments (no true difference between groups)\n",
        "rng = np.random.default_rng(11088)\n",
        "p_values = []\n",
        "\n",
        "n_per_group = 30\n",
        "n_sim = 10000\n",
        "\n",
        "for _ in range(n_sim):\n",
        "    x = rng.normal(0, 1, n_per_group)\n",
        "    y = rng.normal(0, 1, n_per_group)\n",
        "    _, p = st.ttest_ind(x, y, equal_var=False)\n",
        "    p_values.append(p)\n",
        "\n",
        "alpha_1 = 0.05\n",
        "alpha_2 = 0.0314\n",
        "\n",
        "sns.histplot(p_values, bins=30)\n",
        "plt.axvline(alpha_1, linestyle=\"--\", label=\"0.05\")\n",
        "plt.axvline(alpha_2, linestyle=\":\", label=\"0.0314\")\n",
        "plt.title(\"Distribution of p-values when there is NO true effect\")\n",
        "plt.xlabel(\"p-value\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "prop_005 = np.mean(np.array(p_values) < alpha_1)\n",
        "prop_0314 = np.mean(np.array(p_values) < alpha_2)\n",
        "\n",
        "print(f\"Proportion of p-values < 0.05:   {prop_005:5.3f}\")\n",
        "print(f\"Proportion of p-values < 0.0314: {prop_0314:5.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "pvalue_reflection_text",
      "source": [
        "**Reflection**\n",
        "\n",
        "- Roughly what proportion of p-values fall below 0.05 when H0 is true?  \n",
        "- What happens when we tighten the threshold to 0.0314?  \n",
        "- What does this tell you about treating p = 0.049 and p = 0.051 as fundamentally different?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "two_groups_text",
      "source": [
        "## 8. Comparing two groups: parametric and non-parametric tests\n",
        "\n",
        "We now compare **BP change** between two coffee arms (e.g. low vs high).\n",
        "\n",
        "- **Parametric test**: independent-samples *t*-test (assumes approximate normality and reasonable variance behaviour).  \n",
        "- **Non-parametric test**: Mann–Whitney U test (uses ranks; does not assume normality).\n",
        "\n",
        "We will use **α = 0.0314** as our decision threshold.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "two_groups_code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Select two arms for comparison: low vs high coffee\n",
        "bp_low = df[df[\"coffee_arm\"] == \"low\"][\"bp_change\"].dropna()\n",
        "bp_high = df[df[\"coffee_arm\"] == \"high\"][\"bp_change\"].dropna()\n",
        "\n",
        "# Independent-samples t-test (Welch)\n",
        "t_stat, p_t = st.ttest_ind(bp_low, bp_high, equal_var=False)\n",
        "\n",
        "# Mann–Whitney U test (non-parametric)\n",
        "u_stat, p_u = st.mannwhitneyu(bp_low, bp_high, alternative=\"two-sided\")\n",
        "\n",
        "alpha = 0.0314\n",
        "\n",
        "print(f\"t-test:       t = {t_stat:6.3f}, p = {p_t:6.4f}\")\n",
        "print(f\"Mann–Whitney: U = {u_stat:6.1f}, p = {p_u:6.4f}\")\n",
        "print(f\"Using alpha = {alpha}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "two_groups_questions_text",
      "source": [
        "**Questions**\n",
        "\n",
        "- Do the conclusions from the *t*-test and Mann–Whitney test agree at α = 0.0314?  \n",
        "- Would your conclusion change if you (arbitrarily) switched to α = 0.05?  \n",
        "- Looking back at the distributions, does a parametric or non-parametric test seem more appropriate?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "multi_groups_text",
      "source": [
        "## 9. Comparing more than two groups\n",
        "\n",
        "Now consider **blood glucose** across the three cereal arms:\n",
        "\n",
        "- bran  \n",
        "- cornflakes  \n",
        "- muesli\n",
        "\n",
        "We can use:\n",
        "\n",
        "- **One-way ANOVA** (parametric): compares mean values across groups.  \n",
        "- **Kruskal–Wallis test** (non-parametric): compares distributions using ranks.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "multi_groups_code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "groups_glucose = [group[\"glucose\"].values for _, group in df.groupby(\"cereal_arm\")]\n",
        "\n",
        "# One-way ANOVA\n",
        "f_stat, p_anova = st.f_oneway(*groups_glucose)\n",
        "\n",
        "# Kruskal–Wallis test\n",
        "h_stat, p_kw = st.kruskal(*groups_glucose)\n",
        "\n",
        "print(\"One-way ANOVA:\")\n",
        "print(f\"  F = {f_stat:6.3f}, p = {p_anova:6.4f}\")\n",
        "print(\"Kruskal–Wallis:\")\n",
        "print(f\"  H = {h_stat:6.3f}, p = {p_kw:6.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "multi_groups_boxplot",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Visualise glucose values by cereal arm\n",
        "sns.boxplot(data=df, x=\"cereal_arm\", y=\"glucose\")\n",
        "plt.title(\"Blood glucose by cereal arm\")\n",
        "plt.xlabel(\"Cereal arm\")\n",
        "plt.ylabel(\"Glucose (arbitrary units)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "categorical_comparison_text",
      "source": [
        "## 10. Comparing categories: chi-squared tests and a warning\n",
        "\n",
        "Sometimes we want to know whether **two categorical variables are associated**, for example:\n",
        "\n",
        "- Is the proportion of participants with **high appetite** different across **test foods**?\n",
        "\n",
        "For this we can use a **chi-squared test of independence** on a contingency table.\n",
        "\n",
        "⚠️ **Important reminder:**  \n",
        "- **Categorical** and **ordinal** data should **not** be analysed as if they were continuous without careful justification.  \n",
        "- For example, treating a 5-point Likert scale as if it were a continuous variable and running a *t*-test can be misleading.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "id": "chi_squared_code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Create a simple categorical outcome: high vs not-high appetite\n",
        "high_cutoff = 70\n",
        "df[\"appetite_high\"] = (df[\"appetite_vas\"] >= high_cutoff).astype(int)\n",
        "\n",
        "# Contingency table: appetite_high by food_arm\n",
        "table = pd.crosstab(df[\"appetite_high\"], df[\"food_arm\"])\n",
        "print(\"Contingency table (rows: appetite_high, columns: food_arm):\")\n",
        "display(table)\n",
        "\n",
        "# Chi-squared test of independence\n",
        "chi2, p_chi, dof, expected = st.chi2_contingency(table)\n",
        "\n",
        "print(f\"Chi-squared test: chi2 = {chi2:6.3f}, df = {dof}, p = {p_chi:6.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "chi_squared_reflection_text",
      "source": [
        "**Questions**\n",
        "\n",
        "- Does the chi-squared test suggest a difference in the proportion of high appetite across test foods (using α = 0.0314)?  \n",
        "- How would you **report** this result in words?  \n",
        "- Why is a chi-squared test more appropriate here than a *t*-test on the raw VAS scores split into two categories?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "tools_not_oracle_text",
      "source": [
        "## 11. Statistics: tools, not an oracle\n",
        "\n",
        "Finally, a reminder:\n",
        "\n",
        "- Statistical methods help us **summarise uncertainty** and **quantify evidence**.  \n",
        "- They do **not** replace judgement about study design, data quality, or plausibility.  \n",
        "- A \"significant\" p-value does not guarantee truth, and a \"non-significant\" result does not prove there is no effect.\n",
        "\n",
        "When using these tools in real research, always consider:\n",
        "\n",
        "- Are the data appropriate for the method?  \n",
        "- Are the assumptions at least approximately met?  \n",
        "- Do the results make sense in the context of other evidence?\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
