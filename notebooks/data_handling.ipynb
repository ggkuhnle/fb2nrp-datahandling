{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro_data_handling",
      "metadata": {},
      "source": [
        "# Data Handling and Basic Analysis (FB2NRP)\n",
        "*Version 0.2.0*\n",
        "\n",
        "This workbook introduces the foundations of **data handling and basic analysis**, using a small **synthetic RCT dataset** that mimics some nutrition trials:\n",
        "\n",
        "- Blood pressure change after different amounts of coffee  \n",
        "- Blood glucose after different cereals  \n",
        "- Appetite VAS after different test foods  \n",
        "\n",
        "The data are **simulated** (not real student data) and include **age** and **sex**.  \n",
        "The dataset is made available as a pandas DataFrame called `df` by the **bootstrap cell above**.\n",
        "\n",
        "By the end of the workbook you should be able to:\n",
        "\n",
        "- Distinguish between **categorical**, **ordinal**, and **continuous** variables  \n",
        "- Explore a dataset with `df.info()` and `df.describe()`  \n",
        "- Compute and report **mean**, **SD**, **median**, **IQR** for continuous data  \n",
        "- Explore **distributions** and use Q–Q plots to assess normality  \n",
        "- Create **contingency tables** for categorical data  \n",
        "- Describe data appropriately for publication (e.g. a simple **Table 1**)  \n",
        "- Understand the basics of **NHST** (H0 vs H1), **p-values**, and **95% CIs**  \n",
        "- See why p = 0.05 is not a magical threshold (we will use **α = 0.0314**)  \n",
        "- Compare two and more groups using **parametric** and **non-parametric** tests  \n",
        "- Remember that **statistics are tools, not an oracle**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "flow_of_analysis",
      "metadata": {},
      "source": [
        "## 0. From raw data to analysis: the basic flow\n",
        "\n",
        "In almost every quantitative study, the **flow of analysis** is:\n",
        "\n",
        "1. **View the data**  \n",
        "   - Load the dataset into your software (here: pandas DataFrame `df`).  \n",
        "   - Look at a few rows (`df.head()`).  \n",
        "   - Check variable names, data types, and obvious issues (`df.info()`).\n",
        "\n",
        "2. **Clean the data**  \n",
        "   - Handle missing values (decide when to impute, when to drop).  \n",
        "   - Detect obviously impossible values (e.g. age = −5, VAS > 100).  \n",
        "   - Fix coding problems (e.g. \"Male\" vs \"M\" vs \"m\").\n",
        "\n",
        "3. **Standardise the data**  \n",
        "   - Ensure variables use **consistent units** (e.g. all blood pressure in mmHg, all glucose in mmol/L).  \n",
        "   - Recode categories in a consistent way (e.g. `F`/`M`, or 0/1 with clear labels).\n",
        "\n",
        "4. **Analyse the data**  \n",
        "   - Start with **descriptive statistics** (means, medians, counts, percentages).  \n",
        "   - Present a clear **Table 1** of baseline characteristics.  \n",
        "   - Move to **statistical inference** (p-values, confidence intervals, models) only once you understand the data.\n",
        "\n",
        "In this workbook we follow the same structure: first **understand and describe**, then **compare and infer**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bootstrap_cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# FB2NRP bootstrap cell (works both locally and in Colab)\n",
        "#\n",
        "# What this cell does:\n",
        "# - Locally: expects you to open the notebook from *inside*\n",
        "#   the fb2nrp-datahandling repository (e.g. repo/notebooks).\n",
        "#   It walks up the directory tree to find scripts/bootstrap.py.\n",
        "# - In Colab: if the repo is not found, it clones it from GitHub\n",
        "#   into /content/fb2nrp-datahandling.\n",
        "# - Loads and runs scripts/bootstrap.py.\n",
        "# - Generates a synthetic dataset and makes it available as `df`.\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import pathlib\n",
        "import subprocess\n",
        "import importlib.util\n",
        "\n",
        "REPO_URL = \"https://github.com/ggkuhnle/fb2nrp-datahandling.git\"\n",
        "REPO_DIR = \"fb2nrp-datahandling\"\n",
        "\n",
        "def in_colab() -> bool:\n",
        "    \"\"\"Return True if running inside Google Colab.\"\"\"\n",
        "    try:\n",
        "        import google.colab  # type: ignore  # noqa: F401\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "# Make sure the process cwd is valid\n",
        "try:\n",
        "    cwd = pathlib.Path.cwd()\n",
        "except FileNotFoundError:\n",
        "    raise RuntimeError(\n",
        "        \"Current working directory no longer exists.\\n\"\n",
        "        \"Please restart the kernel from inside the fb2nrp-datahandling repository \"\n",
        "        \"(e.g. open the notebook from repo/notebooks and try again).\"\n",
        "    )\n",
        "\n",
        "# Try to find the repo root by walking up the directory tree\n",
        "repo_root = None\n",
        "for parent in [cwd] + list(cwd.parents):\n",
        "    if (parent / \"scripts\" / \"bootstrap.py\").is_file():\n",
        "        repo_root = parent\n",
        "        break\n",
        "\n",
        "if repo_root is not None:\n",
        "    # We are somewhere inside an existing clone (local or Colab)\n",
        "    os.chdir(repo_root)\n",
        "    repo_root = pathlib.Path.cwd()\n",
        "    print(f\"Repository root detected at: {repo_root}\")\n",
        "else:\n",
        "    # Repo not found by walking up\n",
        "    if in_colab():\n",
        "        # In Colab: clone into /content/fb2nrp-datahandling\n",
        "        base_dir = pathlib.Path(\"/content\")\n",
        "        os.chdir(base_dir)\n",
        "        repo_root = base_dir / REPO_DIR\n",
        "        if not repo_root.is_dir():\n",
        "            print(f\"Cloning repository from {REPO_URL} into {repo_root} ...\")\n",
        "            subprocess.run([\"git\", \"clone\", REPO_URL, str(repo_root)], check=True)\n",
        "        else:\n",
        "            print(f\"Using existing repository at {repo_root}\")\n",
        "        os.chdir(repo_root)\n",
        "        repo_root = pathlib.Path.cwd()\n",
        "        print(f\"Repository root set to: {repo_root}\")\n",
        "    else:\n",
        "        # Local but not inside the repo: fail with a clear message\n",
        "        raise RuntimeError(\n",
        "            \"Could not find fb2nrp-datahandling repository root.\\n\"\n",
        "            \"Please make sure you open this notebook from inside the \"\n",
        "            \"`fb2nrp-datahandling` repository (e.g. repo/notebooks) and \"\n",
        "            \"then re-run this cell.\"\n",
        "        )\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2. Load scripts/bootstrap.py as a module and call init()\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "bootstrap_path = repo_root / \"scripts\" / \"bootstrap.py\"\n",
        "\n",
        "if not bootstrap_path.is_file():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Could not find {bootstrap_path}. \"\n",
        "        \"Please check that the fb2nrp-datahandling repository structure is intact.\"\n",
        "    )\n",
        "\n",
        "spec = importlib.util.spec_from_file_location(\"fb2nrp_bootstrap\", bootstrap_path)\n",
        "bootstrap = importlib.util.module_from_spec(spec)\n",
        "sys.modules[\"fb2nrp_bootstrap\"] = bootstrap\n",
        "spec.loader.exec_module(bootstrap)\n",
        "\n",
        "# CTX will contain paths and settings defined in bootstrap.py\n",
        "CTX = bootstrap.init()\n",
        "\n",
        "for name in [\"REPO_NAME\", \"REPO_URL\"]:\n",
        "    if hasattr(bootstrap, name):\n",
        "        globals()[name] = getattr(bootstrap, name)\n",
        "\n",
        "print(\"Bootstrap completed successfully.\")\n",
        "print(\"The context object is available as `CTX`.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "setup_imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Setup: scientific Python libraries and plotting style\n",
        "#\n",
        "# Assumes the bootstrap cell above has already created:\n",
        "#   - CTX : context object with paths and settings\n",
        "# ============================================================\n",
        "\n",
        "# Data handling and numerical computing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Statistical tests\n",
        "import scipy.stats as st\n",
        "\n",
        "# Display options (optional but helpful)\n",
        "pd.set_option(\"display.max_rows\", 20)\n",
        "pd.set_option(\"display.max_columns\", 20)\n",
        "\n        # Plot style\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
        "\n",
        "print(\"Libraries loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "simulate_data",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Generate the synthetic dataset for this workbook\n",
        "# ============================================================\n",
        "\n        # The helper function simulate_practical_data() returns a\n",
        "# small DataFrame that mimics some nutrition RCT practicals.\n",
        "from scripts.helpers import simulate_practical_data, VARIABLES\n",
        "\n",
        "# Use a fixed seed for reproducibility\n",
        "df = simulate_practical_data(seed=11088)\n",
        "\n",
        "print(f\"Dataset loaded with {len(df)} rows and {df.shape[1]} columns.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "variables_types_text",
      "metadata": {},
      "source": [
        "## 1. Study variables and data types\n",
        "\n",
        "Before running any analysis, we need to understand **what kind of variables** we have.\n",
        "\n",
        "Three common kinds in nutrition and public health:\n",
        "\n",
        "- **Categorical (nominal)**  \n",
        "  - Categories with **no natural order**.  \n",
        "  - Examples: sex (F/M), cereal arm (bran/cornflakes/muesli), country.  \n",
        "  - You can count percentages, but the categories are just **labels**.\n",
        "\n",
        "- **Ordinal**  \n",
        "  - Categories **with a natural order**, but unknown distance between levels.  \n",
        "  - Examples: Likert scales (\"strongly disagree\" to \"strongly agree\"), pain scores 0–10, appetite ratings \"low/medium/high\".  \n",
        "  - You can say that one category is *higher* than another, but you cannot assume equal spacing.\n",
        "\n",
        "- **Continuous (or approximately continuous)**  \n",
        "  - Numeric values where **differences and averages make sense**.  \n",
        "  - Examples: age (years), blood pressure (mmHg), glucose (mmol/L), VAS scores.  \n",
        "  - Often modelled using distributions (normal, log-normal, etc.).\n",
        "\n",
        "Our synthetic dataset `df` contains (one row per participant):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "variables_table",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Overview of variables (from helper metadata)\n",
        "VARIABLES"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "variable_examples",
      "metadata": {},
      "source": [
        "### 1.1 Extra examples of variable types\n",
        "\n",
        "A few more examples to anchor the idea:\n",
        "\n",
        "- **Categorical (nominal)**  \n",
        "  - Test food: *apple*, *biscuit*, *yoghurt*  \n",
        "  - Country of birth: *UK*, *Germany*, *Kenya*, ...  \n",
        "  - Favourite animal: *dog*, *cat*, *(small hippo)*  \n",
        "\n",
        "- **Ordinal**  \n",
        "  - 5-point satisfaction scale: 1 = *very dissatisfied*, ..., 5 = *very satisfied*.  \n",
        "  - Hunger score: *not hungry*, *a bit hungry*, *very hungry*.  \n",
        "  - Pain scale 0–10 (strictly speaking, this is between ordinal and continuous in practice).\n",
        "\n",
        "- **Continuous**  \n",
        "  - Weight in kg, height in cm, BMI in kg/m².  \n",
        "  - Systolic blood pressure in mmHg.  \n",
        "  - VAS appetite 0–100.\n",
        "\n",
        "Correctly identifying variable types matters because it drives the choice of **summary statistics** and **statistical tests**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "first_look_text",
      "metadata": {},
      "source": [
        "## 2. First look at the dataset\n",
        "\n",
        "We start with a **quick overview** of `df`:\n",
        "\n",
        "- `df.head()` shows the first few rows (useful to spot obvious coding issues).  \n",
        "- `df.info()` summarises variables, data types, and missing values.  \n",
        "\n",
        "This is the **\"view\"** step of the analysis flow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "head_cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# First few rows of the dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "info_cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Overall structure of the DataFrame (types, missingness)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "missing_values_text",
      "metadata": {},
      "source": [
        "### 2.1 Missing values and impossible values\n",
        "\n",
        "We should also check for **missing values** and obviously **impossible values** (e.g. negative age, VAS > 100, glucose = 0 in a living participant).\n",
        "\n",
        "Our simulator does not generate missing or impossible values, but in real data these checks are essential and sometimes the longest part of the analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "missing_values_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count of missing values per variable\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "continuous_overview",
      "metadata": {},
      "source": [
        "## 3. How to describe continuous data\n",
        "\n",
        "When describing continuous variables (e.g. **age**, **blood pressure**, **glucose**, **VAS**), we usually talk about two things:\n",
        "\n",
        "1. **Central tendency** – where the values \"tend\" to lie.  \n",
        "2. **Dispersion (spread)** – how much values vary around the centre.\n",
        "\n",
        "Common measures are:\n",
        "\n",
        "- **Mean** (average) and **standard deviation (SD)**  \n",
        "  - Most useful when the distribution is roughly symmetric and not too heavy-tailed.  \n",
        "- **Median** and **interquartile range (IQR)**  \n",
        "  - More robust to skewed distributions and outliers.\n",
        "\n",
        "Later we will also look at **distributions** (normal vs skewed vs log-normal) and the difference between **sample** and **population** quantities."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mean_median_details",
      "metadata": {},
      "source": [
        "### 3.1 Mean, SD, median, and IQR\n",
        "\n",
        "- **Mean**: add up all observations and divide by the number of observations.  \n",
        "- **Standard deviation (SD)**: tells you how far, on average, observations are from the mean.  \n",
        "- **Median**: the middle value when the data are ordered (50% below, 50% above).  \n",
        "- **Interquartile range (IQR)**: difference between the 75th (Q3) and 25th percentile (Q1).  \n",
        "\n",
        "Rules of thumb:\n",
        "\n",
        "- If the distribution is **roughly symmetric** → report *mean ± SD*.  \n",
        "- If the distribution is **clearly skewed** → report *median (IQR)*.  \n",
        "- In practice, many papers report both, especially in supplementary material."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "distribution_and_qq",
      "metadata": {},
      "source": [
        "### 3.2 Distributions and Q–Q plots\n",
        "\n",
        "Two common shapes for continuous data:\n",
        "\n",
        "- **Approximately normal (Gaussian)**  \n",
        "  - Symmetric, bell-shaped.  \n",
        "  - Example: height in adults, measurement error (often).  \n",
        "\n",
        "- **Skewed / log-normal**  \n",
        "  - Long tail to one side (often to the right).  \n",
        "  - Example: some biomarkers, income, concentration data.\n",
        "\n",
        "To assess normality we can use:\n",
        "\n",
        "- **Histograms and density plots** (visual).  \n",
        "- **Q–Q plots (Quantile–Quantile plots)**: compare the quantiles of your data to those of a perfect normal distribution.  \n",
        "\n",
        "If the data are approximately normal, the points in the Q–Q plot lie roughly on a straight line. S-shaped curves or strong deviations in the tails suggest skewness or heavier tails."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sample_population_sem",
      "metadata": {},
      "source": [
        "### 3.3 Sample vs population and the standard error of the mean (SEM)\n",
        "\n",
        "In practice we almost never observe the **entire population**. We observe a **sample** and use it to say something about the population.\n",
        "\n",
        "- **Population mean (μ)**: the true average in the entire population (usually unknown).  \n",
        "- **Sample mean (x̄)**: the average in our sample.  \n",
        "\n",
        "If we repeatedly took new samples of the same size and calculated the mean each time, those sample means would vary.\n",
        "\n",
        "- The **standard deviation (SD)** describes variability **between individuals**.  \n",
        "- The **standard error of the mean (SEM)** describes variability **between sample means**.  \n",
        "\n",
        "For a sample of size *n*, and sample SD = *s*, a common estimate is:\n",
        "\n",
        "$$\\text{SEM} \\approx \\frac{s}{\\sqrt{n}}.$$  \n",
        "\n",
        "SEM is mainly used when constructing **confidence intervals** and performing **hypothesis tests**, not for describing raw data in a Table 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "describe_cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic summary statistics for numeric variables\n",
        "# (mean, SD, min, max, quartiles)\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "descriptive_cont_text",
      "metadata": {},
      "source": [
        "### 3.4 Descriptive statistics for key continuous outcomes\n",
        "\n",
        "Let us compute both mean/SD and median/IQR for the three main continuous outcomes:\n",
        "\n",
        "- `bp_change`  \n",
        "- `glucose`  \n",
        "- `appetite_vas`\n",
        "\n",
        "This table is close to what you might include in a **results section** or a **Table 1**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "descriptive_cont_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "cont_vars = [\"bp_change\", \"glucose\", \"appetite_vas\"]\n",
        "rows = []\n",
        "\n",
        "for var in cont_vars:\n",
        "    series = df[var].dropna()\n",
        "    mean = series.mean()\n",
        "    sd = series.std()\n",
        "    median = series.median()\n",
        "    q1 = series.quantile(0.25)\n",
        "    q3 = series.quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    rows.append({\n",
        "        \"variable\": var,\n",
        "        \"mean\": mean,\n",
        "        \"sd\": sd,\n",
        "        \"median\": median,\n",
        "        \"q1\": q1,\n",
        "        \"q3\": q3,\n",
        "        \"iqr\": iqr\n",
        "    })\n",
        "\n",
        "summary_cont = pd.DataFrame(rows)\n",
        "summary_cont"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "distributions_text",
      "metadata": {},
      "source": [
        "## 4. Exploring distributions\n",
        "\n",
        "Choice of statistical test depends strongly on the **shape of the distribution**.\n",
        "\n",
        "For each continuous outcome we can:\n",
        "\n",
        "- Plot **histograms** and **density curves** (to see skew, multimodality, outliers).  \n",
        "- Use a **Q–Q plot** to compare the data to a perfect normal distribution.  \n",
        "- Compare distributions across arms using **boxplots**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hist_bp_change",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Histogram and density for blood pressure change\n",
        "sns.histplot(df[\"bp_change\"], kde=True)\n",
        "plt.title(\"Distribution of BP change\")\n",
        "plt.xlabel(\"BP change (mmHg)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qqplot_explanation",
      "metadata": {},
      "source": [
        "### 4.1 Q–Q plot in practice\n",
        "\n",
        "Below we use a Q–Q plot for `bp_change`. If the points follow the straight reference line reasonably well (especially in the middle), the data are **not wildly inconsistent** with a normal distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qqplot_bp_change",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Q–Q plot to assess normality of BP change\n",
        "st.probplot(df[\"bp_change\"], dist=\"norm\", plot=plt)\n",
        "plt.title(\"Q–Q plot of BP change\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "boxplot_bp_coffee",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Boxplot of BP change by coffee arm\n",
        "sns.boxplot(data=df, x=\"coffee_arm\", y=\"bp_change\")\n",
        "plt.title(\"BP change by coffee intervention arm\")\n",
        "plt.xlabel(\"Coffee arm\")\n",
        "plt.ylabel(\"BP change (mmHg)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "categorical_descriptive_text",
      "metadata": {},
      "source": [
        "## 5. Categorical variables: nominal vs ordinal\n",
        "\n",
        "For **categorical variables** we usually report **counts and percentages**.\n",
        "\n",
        "Two subclasses are important:\n",
        "\n",
        "- **Nominal** (unordered)  \n",
        "  - Examples: sex (F/M), cereal arm, country, favourite snack.  \n",
        "  - The labels have no inherent ranking.\n",
        "\n",
        "- **Ordinal** (ordered)  \n",
        "  - Examples: Likert scales, symptom severity (mild/moderate/severe).  \n",
        "  - There is a natural order, but the distance between categories is not known.\n",
        "\n",
        "### 5.1 Why not just convert categories into numbers and treat them as continuous?\n",
        "\n",
        "It is tempting to code categories as numbers (e.g. *apple* = 1, *biscuit* = 2, *yoghurt* = 3) and then compute a mean.\n",
        "\n",
        "This is **usually a bad idea** because:\n",
        "\n",
        "- The numerical codes are **arbitrary labels**, not real quantities.  \n",
        "- The differences between codes (2 − 1 vs 3 − 2) have **no scientific meaning**.  \n",
        "- Treating them as continuous in a *t*-test or regression can give misleading results.\n",
        "\n",
        "Instead, we summarise categorical variables using **counts**, **percentages**, and **contingency tables**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "categorical_value_counts",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution of participants by coffee arm (counts)\n",
        "df[\"coffee_arm\"].value_counts().to_frame(name=\"count\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "categorical_crosstab",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contingency table: sex by coffee arm\n",
        "pd.crosstab(df[\"sex\"], df[\"coffee_arm\"], margins=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "table1_intro",
      "metadata": {},
      "source": [
        "## 6. Data description as \"Table 1\"\n",
        "\n",
        "Most clinical and nutrition papers include a **Table 1** that describes the **baseline characteristics** of the study sample.\n",
        "\n",
        "Typical elements:\n",
        "\n",
        "- A column for **\"All participants\"**.  \n",
        "- Additional columns for **treatment arms** (or exposure groups).  \n",
        "- Rows for key variables: age, sex, BMI, main outcomes, etc.  \n",
        "- Continuous variables shown as *mean ± SD* or *median (IQR)*.  \n",
        "- Categorical variables shown as *n (%)*.\n",
        "\n",
        "Below we build a **very simple Table 1** describing age and sex by coffee arm. This is for illustration only – in real work you would usually format the table more nicely (e.g. for LaTeX or Word)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "table1_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple Table 1: age and sex by coffee arm\n",
        "\n",
        "group_var = \"coffee_arm\"\n",
        "continuous_vars = [\"age\"]\n",
        "categorical_vars = [\"sex\"]\n",
        "\n",
        "arms = df[group_var].unique()\n",
        "arms.sort()\n",
        "\n",
        "table1_rows = []\n",
        "\n",
        "# Continuous variables: report mean ± SD\n",
        "for var in continuous_vars:\n",
        "    row = {\"variable\": var, \"type\": \"continuous\"}\n",
        "    for arm in arms:\n",
        "        sub = df[df[group_var] == arm][var].dropna()\n",
        "        m = sub.mean()\n",
        "        s = sub.std()\n",
        "        row[arm] = f\"{m:.1f} ± {s:.1f}\"\n",
        "    table1_rows.append(row)\n",
        "\n",
        "# Categorical variables: report n (%)\n",
        "for var in categorical_vars:\n",
        "    levels = df[var].dropna().unique()\n",
        "    levels.sort()\n",
        "    for level in levels:\n",
        "        row = {\n",
        "            \"variable\": f\"{var} = {level}\",\n",
        "            \"type\": \"categorical\"\n",
        "        }\n",
        "        for arm in arms:\n",
        "            sub = df[df[group_var] == arm]\n",
        "            n = (sub[var] == level).sum()\n",
        "            total = len(sub)\n",
        "            perc = 100 * n / total if total > 0 else np.nan\n",
        "            row[arm] = f\"{n} ({perc:.1f}%)\"\n",
        "        table1_rows.append(row)\n",
        "\n",
        "table1 = pd.DataFrame(table1_rows)\n",
        "table1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "publication_description_text",
      "metadata": {},
      "source": [
        "### 6.1 Example text for methods/results\n",
        "\n",
        "Using a table like the one above, you might write in a paper:\n",
        "\n",
        "- *\"Participants had a mean age of 22.1 ± 3.1 years.\"*  \n",
        "- *\"Overall, 40% of participants were male (n = 72/180).\"*  \n",
        "- *\"Baseline blood pressure did not differ meaningfully between coffee arms.\"*\n",
        "\n",
        "The exact wording depends on the study, but the principle is always:\n",
        "\n",
        "- Describe **who** was studied.  \n",
        "- Use **appropriate summaries** for each variable type.  \n",
        "- Make it possible for the reader to judge how well the sample represents the population of interest."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nhst_intro_text",
      "metadata": {},
      "source": [
        "## 7. Statistical inference and NHST\n",
        "\n",
        "So far we have described the **sample**. Statistical inference is about what we can reasonably say about the **underlying population**.\n",
        "\n",
        "In classical **null hypothesis significance testing (NHST)** we:\n",
        "\n",
        "1. Formulate a **null hypothesis (H0)**, usually \"no difference\" or \"no effect\".  \n",
        "2. Formulate an **alternative hypothesis (H1)**, e.g. \"there is a difference\".  \n",
        "3. Choose a test statistic (e.g. a *t*-statistic) and compute it from the data.  \n",
        "4. Compute a **p-value**: the probability (under H0) of observing a result *at least as extreme* as the one we saw.  \n",
        "5. Compare the p-value to a threshold **α** (alpha) to decide whether the result is *compatible* with H0.\n",
        "\n",
        "Example in this workbook:\n",
        "\n",
        "- H0: mean BP change is the same in **low** and **high** coffee arms.  \n",
        "- H1: mean BP change is different in the two arms.\n",
        "\n",
        "We never prove H0 or H1; we simply assess how **compatible** the data are with H0."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pvalue_ci_text",
      "metadata": {},
      "source": [
        "### 7.1 p-values and why 0.05 is not magical\n",
        "\n",
        "- A **p-value** is *not* the probability that H0 is true.  \n",
        "- It is the probability of the observed data (or more extreme) *if H0 were true*.\n",
        "\n",
        "Common misunderstandings:\n",
        "\n",
        "- p = 0.04 does **not** mean there is a 96% chance that the effect is real.  \n",
        "- p = 0.06 does **not** mean \"no effect\".\n",
        "\n",
        "The widely used threshold **α = 0.05** is **just a convention**:\n",
        "\n",
        "- 0.049 and 0.051 are essentially the same in terms of evidence.  \n",
        "- Treating them as \"significant\" vs \"non-significant\" can be misleading.  \n",
        "- In reality, we should look at **effect size**, **uncertainty**, and **context**.\n",
        "\n",
        "In this workbook we deliberately use an unusual threshold **α = 0.0314** to emphasise that the choice of α is arbitrary and should be justified, not blindly copied.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ci_explanation_text",
      "metadata": {},
      "source": [
        "### 7.2 Confidence intervals (CIs)\n",
        "\n",
        "A **95% confidence interval (CI)** for a parameter (e.g. difference in means) is constructed such that, in repeated samples, **95% of such intervals would contain the true parameter**.\n",
        "\n",
        "In practice:\n",
        "\n",
        "- If a 95% CI for a difference **excludes 0**, the corresponding two-sided test at α = 0.05 is \"statistically significant\".  \n",
        "- The CI gives information about **precision** (width of the interval) and **effect size** (where the interval lies).  \n",
        "- CIs are usually more informative than a bare p-value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "example_ci_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: difference in mean BP change between low and high coffee arms\n",
        "\n",
        "bp_low = df[df[\"coffee_arm\"] == \"low\"][\"bp_change\"].dropna()\n",
        "bp_high = df[df[\"coffee_arm\"] == \"high\"][\"bp_change\"].dropna()\n",
        "\n",
        "mean_low = bp_low.mean()\n",
        "mean_high = bp_high.mean()\n",
        "diff = mean_high - mean_low\n",
        "\n",
        "# Standard error for difference in means (Welch t-test style)\n",
        "se_diff = np.sqrt(bp_low.var(ddof=1)/len(bp_low) + bp_high.var(ddof=1)/len(bp_high))\n",
        "\n",
        "# 95% CI using normal approximation (for teaching; in practice use statsmodels)\n",
        "z = 1.96\n",
        "ci_lower = diff - z * se_diff\n",
        "ci_upper = diff + z * se_diff\n",
        "\n",
        "print(f\"Mean BP change (low coffee):  {mean_low:6.2f} mmHg\")\n",
        "print(f\"Mean BP change (high coffee): {mean_high:6.2f} mmHg\")\n",
        "print(f\"Difference (high - low):      {diff:6.2f} mmHg\")\n",
        "print(f\"Approx. 95% CI: [{ci_lower:6.2f}, {ci_upper:6.2f}] mmHg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "alpha_text",
      "metadata": {},
      "source": [
        "### 7.3 Simulating p-values under the null\n",
        "\n",
        "To see what p-values look like when **there is no true effect**, we can simulate many small RCTs where both groups come from the same distribution.\n",
        "\n",
        "If H0 is true and we repeat the experiment many times:\n",
        "\n",
        "- p-values are roughly **uniformly distributed** between 0 and 1.  \n",
        "- The proportion of p-values below α is **approximately α** (e.g. about 5% below 0.05).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pvalue_sim_plot",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate 10 000 null experiments (no true difference between groups)\n",
        "rng = np.random.default_rng(11088)\n",
        "p_values = []\n",
        "\n",
        "n_per_group = 30\n",
        "n_sim = 10000\n",
        "\n",
        "for _ in range(n_sim):\n",
        "    x = rng.normal(0, 1, n_per_group)\n",
        "    y = rng.normal(0, 1, n_per_group)\n",
        "    _, p = st.ttest_ind(x, y, equal_var=False)\n",
        "    p_values.append(p)\n",
        "\n",
        "alpha_1 = 0.05\n",
        "alpha_2 = 0.0314\n",
        "\n",
        "sns.histplot(p_values, bins=30)\n",
        "plt.axvline(alpha_1, linestyle=\"--\", label=\"0.05\")\n",
        "plt.axvline(alpha_2, linestyle=\":\", label=\"0.0314\")\n",
        "plt.title(\"Distribution of p-values when there is NO true effect\")\n",
        "plt.xlabel(\"p-value\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pvalue_sim_props",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Proportion of p-values below each alpha threshold\n",
        "p_values_array = np.array(p_values)\n",
        "prop_005 = np.mean(p_values_array < alpha_1)\n",
        "prop_0314 = np.mean(p_values_array < alpha_2)\n",
        "\n",
        "print(f\"Proportion of p-values < 0.05:   {prop_005:5.3f}\")\n",
        "print(f\"Proportion of p-values < 0.0314: {prop_0314:5.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pvalue_reflection_text",
      "metadata": {},
      "source": [
        "**Reflection**\n",
        "\n",
        "- Roughly what proportion of p-values fall below 0.05 when H0 is true?  \n",
        "- What happens when we tighten the threshold to 0.0314?  \n",
        "- What does this tell you about treating p = 0.049 and p = 0.051 as fundamentally different?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "two_groups_text",
      "metadata": {},
      "source": [
        "## 8. Basic applications: parametric vs non-parametric tests\n",
        "\n",
        "A **parametric test** makes assumptions about the distribution of the data (e.g. normality, similar variances).  \n",
        "A **non-parametric test** usually works on **ranks** and makes fewer distributional assumptions.\n",
        "\n",
        "We now compare **BP change** between two coffee arms (e.g. low vs high):\n",
        "\n",
        "- **Parametric test**: independent-samples *t*-test (Welch).  \n",
        "- **Non-parametric test**: Mann–Whitney U test (Wilcoxon rank-sum).  \n",
        "\n",
        "We will use **α = 0.0314** as our decision threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "two_groups_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select two arms for comparison: low vs high coffee\n",
        "bp_low = df[df[\"coffee_arm\"] == \"low\"][\"bp_change\"].dropna()\n",
        "bp_high = df[df[\"coffee_arm\"] == \"high\"][\"bp_change\"].dropna()\n",
        "\n",
        "# Independent-samples t-test (Welch, unequal variances)\n",
        "t_stat, p_t = st.ttest_ind(bp_low, bp_high, equal_var=False)\n",
        "\n",
        "# Mann–Whitney U test (non-parametric)\n",
        "u_stat, p_u = st.mannwhitneyu(bp_low, bp_high, alternative=\"two-sided\")\n",
        "\n",
        "alpha = 0.0314\n",
        "\n",
        "print(f\"t-test:       t = {t_stat:6.3f}, p = {p_t:6.4f}\")\n",
        "print(f\"Mann–Whitney: U = {u_stat:6.1f}, p = {p_u:6.4f}\")\n",
        "print(f\"Using alpha = {alpha}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "two_groups_questions_text",
      "metadata": {},
      "source": [
        "**Questions**\n",
        "\n",
        "- Do the conclusions from the *t*-test and Mann–Whitney test agree at α = 0.0314?  \n",
        "- Would your conclusion change if you (arbitrarily) switched to α = 0.05?  \n",
        "- Looking back at the distributions, does a parametric or non-parametric test seem more appropriate?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "multi_groups_text",
      "metadata": {},
      "source": [
        "## 9. Comparing more than two groups\n",
        "\n        "Now consider **blood glucose** across the three cereal arms:\n",
        "\n",
        "- bran  \n",
        "- cornflakes  \n",
        "- muesli\n",
        "\n",
        "We can use:\n",
        "\n",
        "- **One-way ANOVA** (parametric): compares mean values across groups.  \n",
        "- **Kruskal–Wallis test** (non-parametric): compares distributions using ranks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "multi_groups_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "groups_glucose = [group[\"glucose\"].values for _, group in df.groupby(\"cereal_arm\")]\n",
        "\n",
        "# One-way ANOVA\n",
        "f_stat, p_anova = st.f_oneway(*groups_glucose)\n",
        "\n",
        "# Kruskal–Wallis test\n",
        "h_stat, p_kw = st.kruskal(*groups_glucose)\n",
        "\n",
        "print(\"One-way ANOVA:\")\n",
        "print(f\"  F = {f_stat:6.3f}, p = {p_anova:6.4f}\")\n",
        "print(\"Kruskal–Wallis:\")\n",
        "print(f\"  H = {h_stat:6.3f}, p = {p_kw:6.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "multi_groups_boxplot",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualise glucose values by cereal arm\n",
        "sns.boxplot(data=df, x=\"cereal_arm\", y=\"glucose\")\n",
        "plt.title(\"Blood glucose by cereal arm\")\n",
        "plt.xlabel(\"Cereal arm\")\n",
        "plt.ylabel(\"Glucose (arbitrary units)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "categorical_comparison_text",
      "metadata": {},
      "source": [
        "## 10. Comparing categories: chi-squared tests and a warning\n",
        "\n",
        "Sometimes we want to know whether **two categorical variables are associated**, for example:\n",
        "\n",
        "- Is the proportion of participants with **high appetite** different across **test foods**?\n",
        "\n",
        "For this we can use a **chi-squared test of independence** on a contingency table.\n",
        "\n",
        "⚠️ **Important reminder:**  \n",
        "- **Categorical** and **ordinal** data should **not** be analysed as if they were continuous without careful justification.  \n",
        "- For example, treating a 5-point Likert scale as if it were a continuous variable and running a *t*-test can be misleading.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "chi_squared_table",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simple categorical outcome: high vs not-high appetite\n",
        "high_cutoff = 70\n",
        "df[\"appetite_high\"] = (df[\"appetite_vas\"] >= high_cutoff).astype(int)\n",
        "\n",
        "# Contingency table: appetite_high by food_arm\n",
        "table = pd.crosstab(df[\"appetite_high\"], df[\"food_arm\"])\n",
        "table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "chi_squared_test",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chi-squared test of independence\n",
        "chi2, p_chi, dof, expected = st.chi2_contingency(table)\n",
        "\n",
        "print(f\"Chi-squared test: chi2 = {chi2:6.3f}, df = {dof}, p = {p_chi:6.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "chi_squared_reflection_text",
      "metadata": {},
      "source": [
        "**Questions**\n",
        "\n",
        "- Does the chi-squared test suggest a difference in the proportion of high appetite across test foods (using α = 0.0314)?  \n",
        "- How would you **report** this result in words?  \n",
        "- Why is a chi-squared test more appropriate here than a *t*-test on the raw VAS scores split into two categories?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tools_not_oracle_text",
      "metadata": {},
      "source": [
        "## 11. Statistics: tools, not an oracle\n",
        "\n",
        "Finally, a reminder:\n",
        "\n",
        "- Statistical methods help us **summarise uncertainty** and **quantify evidence**.  \n",
        "- They do **not** replace judgement about study design, data quality, or plausibility.  \n",
        "- A \"significant\" p-value does not guarantee truth, and a \"non-significant\" result does not prove there is no effect.\n",
        "\n",
        "When using these tools in real research, always consider:\n",
        "\n",
        "- Are the data appropriate for the method?  \n",
        "- Are the assumptions at least approximately met?  \n",
        "- Do the results make sense in the context of other evidence?  \n",
        "- If a friendly statistician or methodologist (or a small hippo) looked over your analysis, would they recognise the decisions you took and why?\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

